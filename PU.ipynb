{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b3c5ba",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d52c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta,date,datetime\n",
    "import copy\n",
    "from scipy import stats\n",
    "import math\n",
    "import collections\n",
    "import importlib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import manifold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "import dgl\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # font family set\n",
    "plt.rcParams['axes.unicode_minus'] = False  # for minus display\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(style='ticks') #set background\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "%config InlineBackend.figure_format = 'svg' #show svg pictures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78cf7ab",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e31ae0",
   "metadata": {},
   "source": [
    "## 2.1 transaction logs & profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pd.read_csv('new_dataset/portrait.csv')\n",
    "profile2 = pd.read_csv('new_dataset/portrait2.csv')\n",
    "profile2['ds'] = pd.to_datetime(profile2['ds'], format='%m/%d/%y').astype(str)\n",
    "profile.drop(columns=['online_time'],inplace=True)\n",
    "profile = profile.merge(profile2[['ds','roleid','online_time']],on=['ds','roleid'])\n",
    "print(profile.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe62497",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = pd.read_csv('new_dataset/trade.csv')\n",
    "positive_samples = pd.read_csv('new_dataset/label.csv')\n",
    "new_positive_samples = pd.read_csv('new_dataset/label2.csv')\n",
    "new_positive_samples = new_positive_samples[new_positive_samples['is_mask']==1]\n",
    "print(len(trade.values))\n",
    "print(len(profile.values))\n",
    "print(len(positive_samples.values)) #very few RMT logs\n",
    "print(len(new_positive_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the positive_samples and trade\n",
    "label_trade=trade.merge(positive_samples,on=['ts','roleid_src','roleid_dst'],how='left',indicator=True)\n",
    "label_trade['label'] = (label_trade['_merge']=='both').astype(int)\n",
    "label_trade.drop(columns='_merge',inplace=True)\n",
    "print(np.sum(label_trade['label'])) \n",
    "label_trade['ds'] = label_trade['ts'].map(lambda x:x.split()[0])\n",
    "#add a constant for reverse sum\n",
    "label_trade['trade_money']=label_trade['trade_money']+0.1 \n",
    "\n",
    "\n",
    "label_trade=label_trade.merge(new_positive_samples,on=['ts','roleid_src','roleid_dst'],how='left',indicator=True)\n",
    "label_trade['label2'] = (label_trade['_merge']=='both').astype(int)\n",
    "print(np.sum(label_trade['label2']))\n",
    "label_trade.drop(columns='_merge',inplace=True)\n",
    "print(label_trade.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2070393",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = merger.merge(profile,left_on=['roleid_src','ds'],right_on=['roleid','ds'])\n",
    "print(len(samples.values))\n",
    "samples = samples.merge(profile,left_on=['roleid_dst','ds'],right_on=['roleid','ds'])\n",
    "print(len(samples.values))\n",
    "samples.sort_values(by='ts',inplace=True)\n",
    "samples.drop(columns=['ds','os_x','os_y','channel_x','channel_y','roleid_x','roleid_y','create_time_x','create_time_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bad8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add samples in the reverse trading direction\n",
    "label_trade_re=label_trade.copy(deep=True)\n",
    "label_trade['reverse']=0\n",
    "label_trade_re['reverse']=1\n",
    "label_trade_re['tmp']=label_trade_re['roleid_src']\n",
    "label_trade_re['roleid_src']=label_trade_re['roleid_dst']\n",
    "label_trade_re['roleid_dst']=label_trade_re['tmp']\n",
    "label_trade_re['trade_money']=-label_trade_re['trade_money'] #the values are positive\n",
    "label_trade_re.drop(columns=['tmp'],inplace=True)\n",
    "merger=pd.concat([label_trade_re,label_trade])\n",
    "\n",
    "#sort transaction logs by time\n",
    "merger.sort_values(by='ts',inplace=True)\n",
    "merger.drop(columns='ds',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature:accumulated virtual money (net money) of a trader\n",
    "node_money=merger.groupby(['roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "node_money.columns=['Id','net_money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reserve the logs from the buyer to the seller\n",
    "merger_1 = merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "merger_1 = merger_1[merger_1['trade_money']>=0]\n",
    "merger_1.drop(columns=['trade_money'],inplace=True)\n",
    "\n",
    "merger['reverse']=merger['reverse'].map(lambda x: 1 if x==0 else -1)\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "merger['ds']=merger['ts'].map(lambda x:x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98491a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the transaction log for use\n",
    "samples = merger.merge(profile,left_on=['roleid_src','ds'],right_on=['roleid','ds'])\n",
    "print(len(samples.values))\n",
    "samples = samples.merge(profile,left_on=['roleid_dst','ds'],right_on=['roleid','ds'])\n",
    "print(len(samples.values))\n",
    "samples.sort_values(by='ts',inplace=True)\n",
    "samples.drop(columns=['ds','os_x','os_y','channel_x','channel_y','roleid_x','roleid_y','create_time_x','create_time_y'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature: trade amount related\n",
    "samples['price']=samples['trade_money']/samples['trade_cnt']\n",
    "tmp = samples.groupby('trade_item',as_index=False)['price'].mean()\n",
    "tmp.columns=['trade_item','avg_price']\n",
    "samples=samples.merge(tmp,on='trade_item')\n",
    "samples['diff_price']=samples['price']-samples['avg_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature: trade pattern related\n",
    "both_samples_4=merger.groupby(['roleid_src','roleid_dst'])['label'].agg('count').reset_index()\n",
    "both_samples_4.columns=['roleid_src','roleid_dst','trade_n_times']\n",
    "print(both_samples_4.columns)\n",
    "\n",
    "both_samples_5=merger.groupby(['roleid_src','roleid_dst','trade_money'])['label'].agg('count').reset_index()\n",
    "both_samples_5.columns=['roleid_src','roleid_dst','trade_money','trade_money_times']\n",
    "print(both_samples_5.columns) \n",
    "\n",
    "both_samples_6=merger.groupby(['roleid_src','roleid_dst','trade_item'])['label'].agg('count').reset_index()\n",
    "both_samples_6.columns=['roleid_src','roleid_dst','trade_item','trade_item_times']\n",
    "print(both_samples_6.columns)\n",
    "\n",
    "merger['ts_pre']=merger.groupby(['roleid_src','roleid_dst'])['ts'].shift(1)\n",
    "merger['ts_between']=pd.to_timedelta(pd.to_datetime(merger['ts']) - pd.to_datetime(merger['ts_pre'])).dt.total_seconds()\n",
    "merger.drop(columns=['ts_pre'],inplace=True)\n",
    "merger.sort_values(by=['roleid_src','roleid_dst','ts'],inplace=True)\n",
    "merger['ts_between'].fillna(method='bfill',inplace=True) \n",
    "print(merger.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature combination for transaction logs\n",
    "samples_1=samples.merge(merger[['roleid_src','roleid_dst','ts','ts_between']],how='left',on=['roleid_src','roleid_dst','ts'])\n",
    "samples_1=samples_1.merge(both_samples_4,how='left',on=['roleid_src','roleid_dst'])\n",
    "samples_1=samples_1.merge(both_samples_5,how='left',on=['roleid_src','roleid_dst','trade_money'])\n",
    "samples_1=samples_1.merge(both_samples_6,how='left',on=['roleid_src','roleid_dst','trade_item'])\n",
    "samples_1=samples_1.merge(node_money,how='left',left_on='roleid_src',right_on='Id')\n",
    "samples_1=samples_1.merge(node_money,how='left',left_on='roleid_dst',right_on='Id')\n",
    "samples_1.drop(columns=['Id_x','Id_y'],inplace=True)\n",
    "print(samples_1.columns)\n",
    "samples_label=samples_1.label\n",
    "samples_1.drop(columns=['label'],inplace=True)\n",
    "samples_1.insert(len(samples_1.columns),'label',samples_label)\n",
    "samples_label=samples_1.label2\n",
    "samples_1.drop(columns=['label2'],inplace=True)\n",
    "samples_1.insert(len(samples_1.columns),'label2',samples_label)\n",
    "print(samples_1.head(5))\n",
    "print(samples_1.info())\n",
    "\n",
    "#filter the transaction sequences with length>1\n",
    "samples_1.sort_values(by='ts',inplace=True)\n",
    "samples_1 = samples_1[samples_1['trade_n_times']>1]\n",
    "print(len(samples_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b80e34",
   "metadata": {},
   "source": [
    "## 2.2 transaction sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggeragte the transaction sequences between pairs of traders\n",
    "#define the aggregating ways of features\n",
    "agg_dict = {}\n",
    "for column in samples_1.columns:\n",
    "    if 'roleid' in column or column =='ts' or column =='trade_item':\n",
    "        continue\n",
    "    elif column in ['trade_money','price','trade_money_times']:\n",
    "        agg_dict[column]=['max','sum']\n",
    "    elif column =='trade_item_times':\n",
    "        agg_dict[column]=['max']\n",
    "    elif column =='ts_between':\n",
    "        agg_dict[column]=['min','mean']\n",
    "        #agg_dict[column]=['min']\n",
    "    elif column =='reverse': \n",
    "        agg_dict[column]=['sum']\n",
    "    else:\n",
    "        agg_dict[column]=['mean']\n",
    "print(agg_dict)\n",
    "        \n",
    "def f(x):\n",
    "    d = {}\n",
    "    for (column,how_list) in agg_dict.items():\n",
    "        for how in how_list:\n",
    "            if how == 'mean':\n",
    "                d[column+'_'+how] = x[column].mean()\n",
    "            elif how == 'min':\n",
    "                d[column+'_'+how] = x[column].min()\n",
    "            elif how == 'max':\n",
    "                d[column+'_'+how] = x[column].max()\n",
    "            elif how == 'sum':\n",
    "                d[column+'_'+how] = x[column].sum()\n",
    "\n",
    "    return pd.Series(d)\n",
    "\n",
    "samples_2 = samples_1.groupby(['roleid_src','roleid_dst']).apply(f).reset_index()\n",
    "samples_2['label']=(samples_2['label_mean']>0).astype(int)\n",
    "samples_2.drop(columns='label_mean',inplace=True)\n",
    "samples_2['label2']=(samples_2['label2_mean']>0).astype(int)\n",
    "samples_2.drop(columns=['label2_mean','is_mask_mean'],inplace=True)\n",
    "print(samples_2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(samples_2))\n",
    "samples_2 = samples_2.merge(merger_1,on=['roleid_src','roleid_dst']) #reserve the samples from the buyer to the seller\n",
    "print(len(samples_2))\n",
    "print(samples_2.columns)\n",
    "print(np.sum(samples_2['label'])) #label for training\n",
    "print(np.sum(samples_2['label2'])) #label for new_recall test\n",
    "\n",
    "samples_3 = samples_2.drop(columns=['level1_x_mean', 'level2_x_mean',\n",
    "       'level3_x_mean', 'level4_x_mean', 'score1_x_mean', 'score2_x_mean',\n",
    "       'exp1_x_mean', 'exp2_x_mean', 'exp3_x_mean', 'online_time_x_mean',\n",
    "       'level1_y_mean', 'level2_y_mean', 'level3_y_mean', 'level4_y_mean',\n",
    "       'score1_y_mean', 'score2_y_mean', 'exp1_y_mean', 'exp2_y_mean',\n",
    "       'exp3_y_mean', 'online_time_y_mean'])  #drop the player profile for cold start reason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcccfca",
   "metadata": {},
   "source": [
    "# 3. Reweighted XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df145fb",
   "metadata": {},
   "source": [
    "## 3.1 train&valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874548db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = samples_3.iloc[:,0:-2] #reserve the role IDs\n",
    "train = samples_3.iloc[:,2:-2]\n",
    "target = samples_3.iloc[:,-2]\n",
    "print(train.shape)\n",
    "print(target.shape)\n",
    "X_train_1, X_test_1, y_train, y_test = train_test_split(train_1, target, test_size = 0.2, random_state = 7)\n",
    "X_train = X_train_1.iloc[:,2:]\n",
    "X_test = X_test_1.iloc[:,2:]\n",
    "\n",
    "new_pos_X = samples_3[(samples_3['label2']==1)&(samples_3['label']==0)].iloc[:,2:-2]\n",
    "new_pos = samples_3[(samples_3['label2']==1)&(samples_3['label']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X_train = X_train[y_train==1]\n",
    "pos_X_train_1 = X_train_1[y_train==1] #reserve the role IDs\n",
    "un_X_train = X_train[y_train==0]\n",
    "un_X_train_1 = X_train_1[y_train==0] #reserve the role IDs\n",
    "pos_X_test = X_test[y_test==1]\n",
    "pos_X_test_1 = X_test_1[y_test==1]\n",
    "un_X_test = X_test[y_test==0]\n",
    "un_X_test_1 = X_test_1[y_test==0]\n",
    "\n",
    "print(pos_X_train.shape)\n",
    "print(pos_X_test.shape)\n",
    "print(un_X_train.shape)\n",
    "print(un_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87459c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a transation graph constructed by positive samples\n",
    "G0 = nx.Graph() #undirected graph\n",
    "for index, row in pos_X_train_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G0.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "for index, row in pos_X_test_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G0.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G0.number_of_nodes())\n",
    "print(G0.number_of_edges())\n",
    "partition = community.best_partition(G0) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G0)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb673b4",
   "metadata": {},
   "source": [
    "## 3.2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75179d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warm start for an epoch\n",
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train, y_train)\n",
    "xgb_normal = copy.deepcopy(bst)\n",
    "\n",
    "train_preds = bst.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new_recall\n",
    "\n",
    "#feature importance\n",
    "plot_importance(xgb_normal)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59933ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_normal.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84796c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "xgb_normal.save_model('./data_gnn/xgb_normal.json')\n",
    "\n",
    "predict_prob = xgb_normal.predict_proba(train)[:,1] \n",
    "predict_label = [1 if value>=thr else 0 for value in predict_prob] \n",
    "samples_2['predict_label'] = predict_label\n",
    "samples_2['predict_prob'] = predict_prob\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse'] \n",
    "tmp=merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "tmp=tmp[tmp['trade_money']>=0]\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "\n",
    "samples_pos=samples_2[samples_2['predict_label']>0]\n",
    "samples_2.drop(columns=['predict_label','predict_prob'],inplace=True)\n",
    "samples_pos=samples_pos.merge(tmp,on=['roleid_src','roleid_dst']) \n",
    "\n",
    "#save the edges(predicted RMTs) for graph construction\n",
    "ns = samples_pos[['roleid_src','roleid_dst','trade_n_times_mean','trade_money']]\n",
    "ns.columns = ['Source','Target','Weight','trade_money'] \n",
    "ns.to_csv('./data_gnn/test_graph_1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83629d65",
   "metadata": {},
   "source": [
    "# 4. TEDn+ without GAT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a71d55",
   "metadata": {},
   "source": [
    "## 4.1 TEDn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227128de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compulate the confidence interval\n",
    "def DKW_bound(x,y,t,m,n,delta=0.1, gamma= 0.01):\n",
    "#     from scipy.stats import norm\n",
    "    \n",
    "#     sigma = 1.0/x - 1.0/m + 1.0/y - 1.0/n \n",
    "    temp = np.sqrt(np.log(1/delta)/2/n) + np.sqrt(np.log(1/delta)/2/m)\n",
    "    bound = temp*(1+gamma)/(y/n)\n",
    "    estimate = t\n",
    "\n",
    "    return estimate, t - bound, t + bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ec613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixture Propotion Estimation (BBE)\n",
    "def top_bin_estimator_count(pdata_probs, udata_probs, udata_targets):\n",
    "    \n",
    "    p_indices = np.argsort(pdata_probs)\n",
    "    sorted_p_probs = pdata_probs[p_indices]\n",
    "    u_indices = np.argsort(udata_probs)\n",
    "    sorted_u_probs = udata_probs[u_indices]\n",
    "    sorted_u_targets = udata_targets[u_indices]\n",
    "\n",
    "    sorted_u_probs = sorted_u_probs[::-1] #sort by asecnding order\n",
    "    sorted_p_probs = sorted_p_probs[::-1]\n",
    "    sorted_u_targets = sorted_u_targets[::-1]\n",
    "    num = len(sorted_u_probs)\n",
    "\n",
    "    plot_arr = []\n",
    "    plot_ratio = []\n",
    "    j = 0\n",
    "    num_u_samples = 0\n",
    "    ideal_plot_arr = []\n",
    "\n",
    "    upper_cfb = []\n",
    "    lower_cfb = []            \n",
    "\n",
    "    i = 0\n",
    "    while (i < num):\n",
    "        start_interval =  sorted_u_probs[i]   \n",
    "        k = i \n",
    "        if (i<num-1 and start_interval> sorted_u_probs[i+1]): \n",
    "            pass\n",
    "        else: \n",
    "            i += 1\n",
    "            continue\n",
    "        if (sorted_u_targets[i]==1):\n",
    "            num_u_samples += 1\n",
    "\n",
    "        while ( j<len(sorted_p_probs) and sorted_p_probs[j] >= start_interval):\n",
    "            j += 1\n",
    "\n",
    "        if j>1 and i > 1:\n",
    "            t = (i)*1.0*len(sorted_p_probs)/j/len(sorted_u_probs)\n",
    "            plot_ratio.append(t)\n",
    "            ideal_plot_arr.append( (i-num_u_samples)*1.0*len(sorted_p_probs)/j/len(sorted_u_probs))\n",
    "            estimate, lower , upper = DKW_bound(i, j, t, len(sorted_u_probs), len(sorted_p_probs),0.2)\n",
    "            plot_arr.append(estimate)\n",
    "            upper_cfb.append( upper)\n",
    "            lower_cfb.append( lower)\n",
    "\n",
    "        i+=1\n",
    "    if (len(upper_cfb) != 0): \n",
    "        mpe_estimate = np.min(upper_cfb)\n",
    "        idx = np.argmin(upper_cfb)\n",
    "\n",
    "        if (plot_arr[idx] != plot_ratio[idx]): \n",
    "            print(\"fallback...\")\n",
    "\n",
    "        return mpe_estimate, idx, plot_arr[idx], lower_cfb, upper_cfb, plot_arr, ideal_plot_arr\n",
    "    else: \n",
    "        # print(\"\")\n",
    "        return 1.0, 1.0, 1.0, [1.0], [1.0], [1.0], [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the reliable negative and suspicious positive samples\n",
    "def rank_inputs(classifier, u_x, alpha):\n",
    "\n",
    "    u_size = len(u_x)\n",
    "    output_probs = classifier.predict_proba(u_x)[:,1]\n",
    "    keep_samples = np.ones_like(output_probs)\n",
    "\n",
    "    #sort the unlabeled samples by asecnding order of prediction scores\n",
    "    sorted_idx = np.argsort(output_probs)\n",
    "    #set the reliable negative samples to 1, and the suspicious positive samples to 0\n",
    "    keep_samples[sorted_idx[u_size - int(alpha*u_size):]] = 0  \n",
    "\n",
    "    return keep_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bcbb1",
   "metadata": {},
   "source": [
    "## 4.2 without RAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    our_mpe_estimate, index, alpha_estimate, lower_bound, \\\n",
    "            upper_bound, plot_arr, ideal_plot_arr = top_bin_estimator_count(pos_probs, unlabeled_probs, unlabeled_targets)\n",
    "    alpha_used = our_mpe_estimate\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = 0.8\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,pos_new,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+len(pos_new))+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_pu = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_pu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e728bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "xgb_pu.save_model('./data_gnn/xgb_pu.json')\n",
    "\n",
    "predict_prob = xgb_pu.predict_proba(train)[:,1] \n",
    "predict_label = [1 if value>=thr else 0 for value in predict_prob] \n",
    "samples_2['predict_label'] = predict_label\n",
    "samples_2['predict_prob'] = predict_prob\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse'] \n",
    "tmp=merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "tmp=tmp[tmp['trade_money']>=0]\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "\n",
    "samples_pos=samples_2[samples_2['predict_label']>0]\n",
    "samples_2.drop(columns=['predict_label','predict_prob'],inplace=True)\n",
    "samples_pos=samples_pos.merge(tmp,on=['roleid_src','roleid_dst']) \n",
    "\n",
    "#save the edges(predicted RMTs) for graph construction\n",
    "ns = samples_pos[['roleid_src','roleid_dst','trade_n_times_mean','trade_money']]\n",
    "ns.columns = ['Source','Target','Weight','trade_money'] \n",
    "ns.to_csv('./data_gnn/test_graph_2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26104c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_pu.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80f546",
   "metadata": {},
   "source": [
    "## 4.3 with RAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reliability Assessment Rules\n",
    "def postCut(keep_samples, un_X, before_G, classifier):  \n",
    "    G1 = copy.deepcopy(before_G)\n",
    "    i = 0\n",
    "    for _,row in un_X[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "        if keep_samples[i] == 0:  #suspicious positive\n",
    "            G1.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "        i+=1\n",
    "    \n",
    "    #Louvain community detection\n",
    "    partition = community.best_partition(G1) \n",
    "    print(\"partition ok\") \n",
    "\n",
    "    size = len(set(partition.values())) #number of communities\n",
    "    print(size)\n",
    "    mod = community.modularity(partition,G1)\n",
    "    print(mod) #modularity \n",
    "    \n",
    "    cnt = {} #count node numbers of each community\n",
    "    for com in set(partition.values()) :\n",
    "        list_nodes = [nodes for nodes in partition.keys() if partition[nodes] == com]\n",
    "        cnt[com] = len(list_nodes)\n",
    "    \n",
    "    score = classifier.predict_proba(un_X.iloc[:,2:])[:,1]\n",
    "    \n",
    "    i = 0\n",
    "    #if meets any of the 4 conditions, select as reliable positive\n",
    "    for _,row in un_X.iterrows():\n",
    "        if keep_samples[i] == 1:\n",
    "            i+=1\n",
    "            continue\n",
    "        \n",
    "        if score[i]>=0.9 or (cnt[partition[row['roleid_src']]]<50 and cnt[partition[row['roleid_dst']]]<50):\n",
    "            i+=1\n",
    "            continue\n",
    "        if row['roleid_src'] in before_G.nodes() or row['roleid_dst'] in before_G.nodes(): \n",
    "            i+=1\n",
    "            continue\n",
    "\n",
    "        if G1.degree(row['roleid_src'])>=30 or G1.degree(row['roleid_dst'])>=30:\n",
    "            i+=1\n",
    "            continue\n",
    "        \n",
    "        keep_samples[i] = -1  #drop the unqualified suspicious positive samples\n",
    "        i+=1\n",
    "        \n",
    "    return keep_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    our_mpe_estimate, index, alpha_estimate, lower_bound, \\\n",
    "            upper_bound, plot_arr, ideal_plot_arr = top_bin_estimator_count(pos_probs, unlabeled_probs, unlabeled_targets)\n",
    "    alpha_used = our_mpe_estimate\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = 0.8\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    keep_samples = postCut(keep_samples, un_X_train_1, G0, bst)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,pos_new,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+len(pos_new))+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_test = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e069730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "xgb_test.save_model('./data_gnn/xgb_test.json')\n",
    "\n",
    "predict_prob = xgb_test.predict_proba(train)[:,1] \n",
    "predict_label = [1 if value>=thr else 0 for value in predict_prob] \n",
    "samples_2['predict_label'] = predict_label\n",
    "samples_2['predict_prob'] = predict_prob\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse'] \n",
    "tmp=merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "tmp=tmp[tmp['trade_money']>=0]\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "\n",
    "samples_pos=samples_2[samples_2['predict_label']>0]\n",
    "samples_2.drop(columns=['predict_label','predict_prob'],inplace=True)\n",
    "samples_pos=samples_pos.merge(tmp,on=['roleid_src','roleid_dst']) \n",
    "\n",
    "#save the edges(predicted RMTs) for graph construction\n",
    "ns = samples_pos[['roleid_src','roleid_dst','trade_n_times_mean','trade_money']]\n",
    "ns.columns = ['Source','Target','Weight','trade_money'] \n",
    "ns.to_csv('./data_gnn/test_graph_3.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79280af",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_test.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ad4e9",
   "metadata": {},
   "source": [
    "# 5. GAT Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3918130a",
   "metadata": {},
   "source": [
    "## 5.1 graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map node IDs to embeddings\n",
    "ids = np.unique(np.concatenate([samples_2['roleid_src'],samples_2['roleid_dst']]))\n",
    "id_dict = {}\n",
    "for i in range(len(ids)):\n",
    "    id_dict[ids[i]] = i\n",
    "\n",
    "input_size = 8\n",
    "features = torch.randn(len(ids),input_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "features = features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = xgb_test.predict_proba(train)[:,1]\n",
    "id1 = torch.from_numpy(np.array([id_dict[x] for x in samples_3['roleid_src']]))\n",
    "id2 = torch.from_numpy(np.array([id_dict[x] for x in samples_3['roleid_dst']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4582a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dgl.DGLGraph()\n",
    "#use RMT prediction score(also tried trade amount/trade frequency) as edge weight\n",
    "g.add_edges(id1,id2,data={'weight':torch.from_numpy(predict_prob)})\n",
    "#add self-loops with weight 1.0\n",
    "g.add_edges(g.nodes(), g.nodes(),data={'weight':torch.ones_like(g.nodes(),dtype=torch.float32)})\n",
    "g = g.to(device)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149daa4a",
   "metadata": {},
   "source": [
    "## 5.2 model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0488e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, device):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim+1, 1, bias=False)  #concat the weight\n",
    "        self.device = device\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z'], edges.data['weight'].unsqueeze(1)], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        return {'e': F.leaky_relu(a)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        #return self.g.ndata.pop('h')\n",
    "        return self.g.ndata['h']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, device, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        self.device = device\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim,self.device))\n",
    "        self.heads = self.heads.to(self.device) #to device!\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ba3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-layer multi-head GAT\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads, device):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads, device)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, out_dim, 1,device)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.layer2(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea18abf",
   "metadata": {},
   "source": [
    "## 5.3 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and test\n",
    "gat = GAT(g,features.shape[1],16,8,2,device) \n",
    "print(gat)\n",
    "\n",
    "test = gat(features)\n",
    "print(test)\n",
    "print(test.shape)\n",
    "print(g)\n",
    "print(g.adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88172b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction loss\n",
    "def reloss(features,g):\n",
    "\n",
    "    adj = np.array(torch.zeros([len(g.nodes()),len(g.nodes())]))  #adj matrix\n",
    "    weight = g.edata['weight'].cpu().numpy()\n",
    "    cpu_features = features.detach().cpu().numpy()\n",
    "\n",
    "    i = 0\n",
    "    for src,dst in zip(g.edges()[0].cpu().numpy(),g.edges()[1].cpu().numpy()):\n",
    "        adj[src][dst] = weight[i]\n",
    "        i+=1\n",
    "    #dot-product as similarity\n",
    "    sim = cpu_features.dot(cpu_features.T)\n",
    "    min_max_scaler = MinMaxScaler() \n",
    "    sim = min_max_scaler.fit_transform(sim)  #normalize\n",
    "\n",
    "    return torch.norm(torch.from_numpy(sim-adj))/len(g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309af662",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(gat.parameters(), lr=0.0001) \n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    gat.train()\n",
    "    optimizer.zero_grad()\n",
    "    features = gat(features)\n",
    "    loss = reloss(features,g).to(device)\n",
    "    loss.requires_grad_(True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Train Epoch: {} \\tloss: {:.6f}'.format(epoch,loss.data.cpu().numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the gat model and trained embeddings\n",
    "torch.save(gat, './data_gnn/gat.pkl')\n",
    "with open('./data_gnn/embeddings', \"a\") as log_file:\n",
    "        np.savetxt(log_file,  features.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3ee13",
   "metadata": {},
   "source": [
    "# 6. TEDn+ with GAT Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6058352",
   "metadata": {},
   "source": [
    "## 6.1 dataset & reweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gat embeddings\n",
    "node_embeddings = pd.DataFrame(features.detach().cpu().numpy())\n",
    "node_embeddings = pd.concat([pd.Series(ids),node_embeddings],axis = 1)\n",
    "columns = ['roleid']\n",
    "for i in range(len(node_embeddings.columns)-1):\n",
    "    columns.append(\"emb_\"+str(i))\n",
    "node_embeddings.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00495ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the node embeddings of the buyer/seller\n",
    "samples_3 = samples_2.merge(node_embeddings,left_on = 'roleid_src',right_on='roleid')\n",
    "samples_3 = samples_3.merge(node_embeddings,left_on = 'roleid_dst',right_on='roleid')\n",
    "label = samples_3.label\n",
    "label_2 = samples_3.label2\n",
    "samples_3.drop(columns=['roleid_x','roleid_y','label','label2'],inplace = True)\n",
    "samples_3.insert(len(samples_3.columns),'label',label)\n",
    "samples_3.insert(len(samples_3.columns),'label2',label_2)\n",
    "#drop the player profile\n",
    "samples_3.drop(columns=['level1_x_mean', 'level2_x_mean',\n",
    "       'level3_x_mean', 'level4_x_mean', 'score1_x_mean', 'score2_x_mean',\n",
    "       'exp1_x_mean', 'exp2_x_mean', 'exp3_x_mean', 'online_time_x_mean',\n",
    "       'level1_y_mean', 'level2_y_mean', 'level3_y_mean', 'level4_y_mean',\n",
    "       'score1_y_mean', 'score2_y_mean', 'exp1_y_mean', 'exp2_y_mean',\n",
    "       'exp3_y_mean', 'online_time_y_mean'],inplace=True)\n",
    "print(samples_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = samples_3.iloc[:,0:-2] #reserve the role IDs\n",
    "train = samples_3.iloc[:,2:-2]\n",
    "target = samples_3.iloc[:,-2]\n",
    "print(train.shape)\n",
    "print(target.shape)\n",
    "X_train_1, X_test_1, y_train, y_test = train_test_split(train_1, target, test_size = 0.2, random_state = 7)\n",
    "X_train = X_train_1.iloc[:,2:]\n",
    "X_test = X_test_1.iloc[:,2:]\n",
    "\n",
    "new_pos_X = samples_3[(samples_3['label2']==1)&(samples_3['label']==0)].iloc[:,2:-2]\n",
    "new_pos = samples_3[(samples_3['label2']==1)&(samples_3['label']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74722b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X_train = X_train[y_train==1]\n",
    "pos_X_train_1 = X_train_1[y_train==1] #reserve the role IDs\n",
    "un_X_train = X_train[y_train==0]\n",
    "un_X_train_1 = X_train_1[y_train==0] #reserve the role IDs\n",
    "pos_X_test = X_test[y_test==1]\n",
    "pos_X_test_1 = X_test_1[y_test==1]\n",
    "un_X_test = X_test[y_test==0]\n",
    "un_X_test_1 = X_test_1[y_test==0]\n",
    "\n",
    "print(pos_X_train.shape)\n",
    "print(pos_X_test.shape)\n",
    "print(un_X_train.shape)\n",
    "print(un_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37950234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warm start for an epoch\n",
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train, y_train)\n",
    "xgb_normal = copy.deepcopy(bst)\n",
    "\n",
    "train_preds = bst.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new_recall\n",
    "\n",
    "#feature importance\n",
    "plot_importance(xgb_normal)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_normal.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "xgb_normal.save_model('./data_gnn/xgb_normal_1.json')\n",
    "\n",
    "predict_prob = xgb_normal.predict_proba(train)[:,1] \n",
    "predict_label = [1 if value>=thr else 0 for value in predict_prob] \n",
    "samples_2['predict_label'] = predict_label\n",
    "samples_2['predict_prob'] = predict_prob\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse'] \n",
    "tmp=merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "tmp=tmp[tmp['trade_money']>=0]\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "\n",
    "samples_pos=samples_2[samples_2['predict_label']>0]\n",
    "samples_2.drop(columns=['predict_label','predict_prob'],inplace=True)\n",
    "samples_pos=samples_pos.merge(tmp,on=['roleid_src','roleid_dst']) \n",
    "\n",
    "#save the edges(predicted RMTs) for graph construction\n",
    "ns = samples_pos[['roleid_src','roleid_dst','trade_n_times_mean','trade_money']]\n",
    "ns.columns = ['Source','Target','Weight','trade_money'] \n",
    "ns.to_csv('./data_gnn/test_graph_4.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f113f85c",
   "metadata": {},
   "source": [
    "## 6.2 without RAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    our_mpe_estimate, index, alpha_estimate, lower_bound, \\\n",
    "            upper_bound, plot_arr, ideal_plot_arr = top_bin_estimator_count(pos_probs, unlabeled_probs, unlabeled_targets)\n",
    "    alpha_used = our_mpe_estimate\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = 0.8\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,pos_new,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+len(pos_new))+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_pu = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_pu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6351b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "xgb_pu.save_model('./data_gnn/xgb_pu_1.json')\n",
    "\n",
    "predict_prob = xgb_pu.predict_proba(train)[:,1] \n",
    "predict_label = [1 if value>=thr else 0 for value in predict_prob] \n",
    "samples_2['predict_label'] = predict_label\n",
    "samples_2['predict_prob'] = predict_prob\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse'] \n",
    "tmp=merger.groupby(['roleid_src','roleid_dst'])['trade_money'].agg('sum').reset_index()\n",
    "tmp=tmp[tmp['trade_money']>=0]\n",
    "merger['trade_money']=merger['trade_money']*merger['reverse']\n",
    "\n",
    "samples_pos=samples_2[samples_2['predict_label']>0]\n",
    "samples_2.drop(columns=['predict_label','predict_prob'],inplace=True)\n",
    "samples_pos=samples_pos.merge(tmp,on=['roleid_src','roleid_dst']) \n",
    "\n",
    "#save the edges(predicted RMTs) for graph construction\n",
    "ns = samples_pos[['roleid_src','roleid_dst','trade_n_times_mean','trade_money']]\n",
    "ns.columns = ['Source','Target','Weight','trade_money'] \n",
    "ns.to_csv('./data_gnn/test_graph_5.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0448680",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_pu.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128ede6",
   "metadata": {},
   "source": [
    "# 7. Other PU Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359d85f",
   "metadata": {},
   "source": [
    "## 7.1 TEDn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b837b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "bst = copy.deepcopy(xgb_normal)\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    our_mpe_estimate, index, alpha_estimate, lower_bound, \\\n",
    "            upper_bound, plot_arr, ideal_plot_arr = top_bin_estimator_count(pos_probs, unlabeled_probs, unlabeled_targets)\n",
    "    alpha_used = our_mpe_estimate\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = 0.8\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and drop the suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_tmp = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bca762",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.4\n",
    "preds = xgb_tmp.predict_proba(train)[:,1]\n",
    "predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87403149",
   "metadata": {},
   "source": [
    "## 7.2 DEDPUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_apply(diff, k_neighbours):\n",
    "    s = pd.Series(diff)\n",
    "    s = np.concatenate((\n",
    "                        s.iloc[:2*k_neighbours].expanding(center=False).median()[::2].values,\n",
    "                        s.rolling(k_neighbours*2+1, center=True).median().dropna().values,\n",
    "                        np.flip(np.flip(s.iloc[-2*k_neighbours:], axis=0).expanding(center=False).median()[::2], axis=0).values\n",
    "    ))\n",
    "    return s\n",
    "\n",
    "\n",
    "class GaussianMixtureNoFit(GaussianMixture):\n",
    "    def __init__(self, n_components=1, covariance_type='full', tol=1e-3,\n",
    "                 reg_covar=1e-6, max_iter=100, n_init=1, init_params='kmeans',\n",
    "                 weights_init=None, means_init=None, precisions_init=None,\n",
    "                 random_state=None, warm_start=False,\n",
    "                 verbose=0, verbose_interval=10, max_components=None):\n",
    "\n",
    "        self.max_components = max_components\n",
    "\n",
    "        idx = np.arange(means_init.shape[0])\n",
    "        if (max_components is not None) and (means_init.shape[0] > max_components):\n",
    "            n_components = min(n_components, max_components)\n",
    "            np.random.shuffle(idx)\n",
    "            idx = idx[:self.max_components]\n",
    "\n",
    "        weights_init = weights_init[idx]\n",
    "        weights_init /= weights_init.sum()\n",
    "        means_init = means_init[idx]\n",
    "        precisions_init = precisions_init[idx]\n",
    "\n",
    "        super().__init__(n_components, covariance_type, tol,\n",
    "                         reg_covar, max_iter, n_init, init_params,\n",
    "                         weights_init, means_init, precisions_init,\n",
    "                         random_state, warm_start,\n",
    "                         verbose, verbose_interval)\n",
    "\n",
    "        self.weights = weights_init\n",
    "        self.means = means_init\n",
    "        self.precisions = precisions_init\n",
    "        self.weights_ = weights_init\n",
    "        self.means_ = means_init\n",
    "        self.precisions_ = precisions_init\n",
    "        self.precisions_cholesky_ = np.sqrt(precisions_init)\n",
    "        self.covariances_ = 1 / precisions_init\n",
    "        self.covariances = 1 / precisions_init\n",
    "\n",
    "    def _initialize(self, X, resp):\n",
    "        pass\n",
    "\n",
    "    def _m_step(self, X, log_resp):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "        return self\n",
    "    \n",
    "\n",
    "def maximize_log_likelihood(preds, kde_inner_fun, kde_outer_fun, n_folds=5, kde_type='kde', bw_low=0.01, bw_high=0.4,\n",
    "                            n_gauss_low=1, n_gauss_high=50, bins_low=20, bins_high=250, n_steps=25):\n",
    "    kf = KFold(n_folds, shuffle=True)\n",
    "    idx_best, like_best = 0, 0\n",
    "    bws = np.exp(np.linspace(np.log(bw_low), np.log(bw_high), n_steps))\n",
    "    n_gauss = np.linspace(n_gauss_low, n_gauss_high, n_steps).astype(int)\n",
    "    bins = np.linspace(bins_low, bins_high, n_steps).astype(int)\n",
    "    for idx, (bw, n_g, bin) in enumerate(zip(bws, n_gauss, bins)):\n",
    "        like = 0\n",
    "        for train_idx, test_idx in kf.split(preds):\n",
    "            if kde_type == 'kde':\n",
    "                kde = gaussian_kde(np.apply_along_axis(kde_inner_fun, 0, preds[train_idx]), bw)\n",
    "            elif kde_type == 'GMM':\n",
    "                GMM = GaussianMixture(n_g, covariance_type='spherical').fit(\n",
    "                    np.apply_along_axis(kde_inner_fun, 0, preds[train_idx]).reshape(-1, 1))\n",
    "                kde = lambda x: np.exp(GMM.score_samples(x.reshape(-1, 1)))\n",
    "            elif kde_type == 'hist':\n",
    "                bars = np.histogram(preds[train_idx], bins=bin, range=(0, 1), density=True)[0]\n",
    "                kde = lambda x: bars[np.clip((x // (1 / bin)).astype(int), 0, bin - 1)]\n",
    "                kde_outer_fun = lambda kde, x: kde(x)\n",
    "\n",
    "            like += compute_log_likelihood(preds[test_idx], kde, kde_outer_fun)\n",
    "        if like > like_best:\n",
    "            like_best, idx_best = like, idx\n",
    "    if kde_type == 'kde':\n",
    "        return bws[idx_best]\n",
    "    elif kde_type == 'GMM':\n",
    "        return n_gauss[idx_best]\n",
    "    elif kde_type == 'hist':\n",
    "        return bins[idx_best]\n",
    "    \n",
    "class MonotonizingTrends:\n",
    "    def __init__(self, a=None, MT_coef=1):\n",
    "        self.counter = dict()\n",
    "        self.array_new = []\n",
    "        if a is None:\n",
    "            self.array_old = []\n",
    "        else:\n",
    "            self.add_array(a)\n",
    "        self.MT_coef = MT_coef\n",
    "\n",
    "    def add_array(self, a):\n",
    "        if isinstance(a, np.ndarray) or isinstance(a, pd.Series):\n",
    "            a = a.tolist()\n",
    "        self.array_old = a\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = dict()\n",
    "        self.array_old = []\n",
    "        self.array_new = []\n",
    "\n",
    "    def get_highest_point(self):\n",
    "        if self.counter:\n",
    "            return max(self.counter)\n",
    "        else:\n",
    "            return np.NaN\n",
    "\n",
    "    def add_point_to_counter(self, point):\n",
    "        if point not in self.counter.keys():\n",
    "            self.counter[point] = 1\n",
    "\n",
    "    def change_counter_according_to_point(self, point):\n",
    "        for key in self.counter.keys():\n",
    "            if key <= point:\n",
    "                self.counter[key] += 1\n",
    "            else:\n",
    "                self.counter[key] -= self.MT_coef\n",
    "\n",
    "    def clear_counter(self):\n",
    "        for key, value in list(self.counter.items()):\n",
    "            if value <= 0:\n",
    "                self.counter.pop(key)\n",
    "\n",
    "    def update_counter_with_point(self, point):\n",
    "        self.change_counter_according_to_point(point)\n",
    "        self.clear_counter()\n",
    "        self.add_point_to_counter(point)\n",
    "\n",
    "    def monotonize_point(self, point=None):\n",
    "        if point is None:\n",
    "            point = self.array_old.pop(0)\n",
    "        new_point = max(point, self.get_highest_point())\n",
    "        self.array_new.append(new_point)\n",
    "        self.update_counter_with_point(point)\n",
    "        return new_point\n",
    "\n",
    "    def monotonize_array(self, a=None, reset=False, decay_MT_coef=False):\n",
    "        if a is not None:\n",
    "            self.add_array(a)\n",
    "        decay_by = 0\n",
    "        if decay_MT_coef:\n",
    "            decay_by = self.MT_coef / len(a)\n",
    "\n",
    "        for _ in range(len(self.array_old)):\n",
    "            self.monotonize_point()\n",
    "            if decay_MT_coef:\n",
    "                self.MT_coef -= decay_by\n",
    "\n",
    "        if not reset:\n",
    "            return self.array_new\n",
    "        else:\n",
    "            array_new = self.array_new[:]\n",
    "            self.reset()\n",
    "            return array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a48b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_preds_cv_xgboost(data, target, random_state=None, n_networks=1,\n",
    "                               cv=3, n_early_stop=10, verbose=False):\n",
    "#     if xgboost_params is None:\n",
    "#         xgboost_params = {}\n",
    "    preds = np.zeros((n_networks, data.shape[0]))\n",
    "    for i in range(n_networks):\n",
    "        kf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "        for train_idx, test_idx in kf.split(data, target):\n",
    "            clf = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=(len(target)-target.sum())//target.sum()) #sklearn api\n",
    "            clf.fit(data[train_idx], target[train_idx],\n",
    "                    eval_set=[(data[test_idx], target[test_idx])], verbose=verbose, early_stopping_rounds=n_early_stop)\n",
    "            preds[i, test_idx] = clf.predict_proba(data[test_idx])[:, 1]\n",
    "        if random_state is not None:\n",
    "            random_state += 1\n",
    "    preds = preds.mean(axis=0)\n",
    "    # preds = np.median(preds, axis=0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_poster_cv(df, target, estimator='dedpul', bayes=False, alpha=None, estimate_poster_options=None,\n",
    "                       estimate_diff_options=None, estimate_preds_cv_options=None, train_nn_options=None):\n",
    "    \"\"\"\n",
    "    Estimates posteriors and priors alpha (if not provided) of N in U; f_u(x) = (1 - alpha) * f_p(x) + alpha * f_n(x)\n",
    "    :param df: features, np.array (n_instances, n_features)\n",
    "    :param target: binary vector, 0 if positive, 1 if unlabeled, np.array with shape (n,)\n",
    "    :param estimator: 'dedpul', 'baseline_dedpul', 'random_dedpul ,'en', 'em_en', or 'nnre';\n",
    "        'ntc_methods' for every estimate but 'nnre'\n",
    "    :param alpha: share of N in U; is estimated if not provided (nnRE requires it to be provided)\n",
    "    :param estimate_poster_options: parameters for estimate_poster... functions\n",
    "    :param estimate_diff_options: parameters for estimate_diff\n",
    "    :param estimate_preds_cv_options: parameters for estimate_preds_cv\n",
    "    :param train_nn_options: parameters for train_NN\n",
    "    :return: if estimator != 'ntc_methods':\n",
    "        tuple (alpha, poster), e.g. (priors, posteriors) of N in U for the U sample df[target == 1]\n",
    "        if estimator == 'ntc_methods':\n",
    "        dictionary with such (alpha, poster) tuples as values and method names as keys\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.values\n",
    "    if isinstance(target, pd.Series):\n",
    "        target = target.values\n",
    "\n",
    "    if estimator == 'nnre':\n",
    "        training_mode = 'nnre'\n",
    "    else:\n",
    "        training_mode = 'standard'\n",
    "\n",
    "    if train_nn_options is None:\n",
    "        train_nn_options = dict()\n",
    "\n",
    "    if estimate_poster_options is None:\n",
    "        estimate_poster_options = dict()\n",
    "\n",
    "    if estimate_diff_options is None:\n",
    "        estimate_diff_options = dict()\n",
    "\n",
    "    if estimate_preds_cv_options is None:\n",
    "        estimate_preds_cv_options = dict()\n",
    "\n",
    "    preds = estimate_preds_cv_xgboost(df, target)\n",
    "    ### uncomment the line above and comment the line below for experiments with catboost instead of neural networks\n",
    "    #preds = estimate_preds_cv(df=df, target=target, alpha=alpha, training_mode=training_mode, bayes=bayes,\n",
    "                              #train_nn_options=train_nn_options, **estimate_preds_cv_options)\n",
    "    if bayes:\n",
    "        preds, means, variances = preds\n",
    "    if estimator in {'dedpul', 'baseline_dedpul', 'ntc_methods'}:\n",
    "        if bayes:\n",
    "            diff = estimate_diff_bayes(means, variances, target, **estimate_diff_options)\n",
    "        else:\n",
    "            diff = estimate_diff(preds, target, **estimate_diff_options)\n",
    "\n",
    "    if estimator == 'dedpul':\n",
    "        alpha, poster = estimate_poster_em(diff=diff, mode='dedpul', alpha=alpha, **estimate_poster_options)\n",
    "\n",
    "    elif estimator == 'baseline_dedpul':\n",
    "        alpha, poster = estimate_poster_dedpul(diff=diff, alpha=alpha, **estimate_poster_options)\n",
    "\n",
    "    elif estimator == 'en':\n",
    "        alpha, poster = estimate_poster_en(preds, target, alpha=alpha, **estimate_poster_options)\n",
    "\n",
    "    elif estimator == 'em_en':\n",
    "        alpha, poster = estimate_poster_em(preds=preds, target=target, mode='en', alpha=alpha, **estimate_poster_options)\n",
    "\n",
    "    elif estimator == 'nnre':\n",
    "        poster = preds[target == 1]\n",
    "\n",
    "    elif estimator == 'ntc_methods':\n",
    "        res = dict()\n",
    "        res['dedpul'] = estimate_poster_em(diff=diff, mode='dedpul', alpha=None, **estimate_poster_options)\n",
    "        res['baseline_dedpul'] = estimate_poster_dedpul(diff=diff, alpha=None, **estimate_poster_options)\n",
    "        res['e1_en'] = estimate_poster_en(preds, target, alpha=None, estimator='e1', **estimate_poster_options)\n",
    "        res['e3_en'] = estimate_poster_en(preds, target, alpha=None, estimator='e3', **estimate_poster_options)\n",
    "        res['em_en'] = estimate_poster_em(preds=preds, target=target, mode='en', alpha=None, **estimate_poster_options)\n",
    "\n",
    "        res['dedpul_poster'] = estimate_poster_em(diff=diff, mode='dedpul', alpha=alpha, **estimate_poster_options)\n",
    "        res['baseline_dedpul_poster'] = estimate_poster_dedpul(diff=diff, alpha=alpha, **estimate_poster_options)\n",
    "        res['e1_en_poster'] = estimate_poster_en(preds, target, alpha=alpha, estimator='e1', **estimate_poster_options)\n",
    "        res['e3_en_poster'] = estimate_poster_en(preds, target, alpha=alpha, estimator='e3', **estimate_poster_options)\n",
    "        res['em_en_poster'] = estimate_poster_em(preds=preds, target=target, mode='en', alpha=alpha, **estimate_poster_options)\n",
    "\n",
    "        return res\n",
    "\n",
    "    return alpha, poster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b21c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_diff(preds, target, bw_mix=0.05, bw_pos=0.1, kde_mode='logit', threshold=None, k_neighbours=None,\n",
    "                  tune=False, MT=True, MT_coef=0.2, decay_MT_coef=False, kde_type='kde',\n",
    "                  n_gauss_mix=20, n_gauss_pos=10, bins_mix=20, bins_pos=20):\n",
    "    \"\"\"\n",
    "    Estimates densities of predictions y(x) for P and U and ratio between them f_p / f_u for U sample;\n",
    "        uses kernel density estimation (kde);\n",
    "        post-processes difference of estimated densities - imposes monotonicity on lower preds\n",
    "        (so that diff is partly non-decreasing) and applies rolling median to further reduce variance\n",
    "    :param preds: predictions of NTC y(x), probability of belonging to U rather than P, np.array with shape (n,)\n",
    "    :param target: binary vector, 0 if positive, 1 if unlabeled, np.array with shape (n,)\n",
    "    :param bw_mix: bandwidth for kde of U\n",
    "    :param bw_pos: bandwidth for kde of P\n",
    "    :param kde_mode: 'prob', 'log_prob' or 'logit'; default is 'logit'\n",
    "    :param monotonicity: monotonicity is imposed on density difference for predictions below this number, float in [0, 1]\n",
    "    :param k_neighbours: difference is relaxed with median rolling window with size k_neighbours * 2 + 1,\n",
    "        default = int(preds[target == 1].shape[0] // 10)\n",
    "\n",
    "    :return: difference of densities f_p / f_u for U sample\n",
    "    \"\"\"\n",
    "\n",
    "    if kde_mode is None:\n",
    "        kde_mode = 'logit'\n",
    "\n",
    "    if (threshold is None) or (threshold == 'mid'):\n",
    "        threshold = preds[target == 1].mean() / 2 + preds[target == 0].mean() / 2\n",
    "    elif threshold == 'low':\n",
    "        threshold = preds[target == 0].mean()\n",
    "    elif threshold == 'high':\n",
    "        threshold = preds[target == 1].mean()\n",
    "\n",
    "    if k_neighbours is None:\n",
    "        k_neighbours = int(preds[target == 1].shape[0] // 20)\n",
    "\n",
    "    if kde_mode == 'prob':\n",
    "        kde_inner_fun = lambda x: x\n",
    "        kde_outer_fun = lambda dens, x: dens(x)\n",
    "    elif kde_mode == 'log_prob':\n",
    "        kde_inner_fun = lambda x: np.log(x)\n",
    "        kde_outer_fun = lambda dens, x: dens(np.log(x)) / (x + 10 ** -5)\n",
    "    elif kde_mode == 'logit':\n",
    "        kde_inner_fun = lambda x: np.log(x / (1 - x + 10 ** -5))\n",
    "        kde_outer_fun = lambda dens, x: dens(np.log(x / (1 - x + 10 ** -5))) / (x * (1 - x) + 10 ** -5)\n",
    "\n",
    "    if kde_type == 'kde':\n",
    "        if tune:\n",
    "            bw_mix = maximize_log_likelihood(preds[target == 1], kde_inner_fun, kde_outer_fun, kde_type=kde_type)\n",
    "            bw_pos = maximize_log_likelihood(preds[target == 0], kde_inner_fun, kde_outer_fun, kde_type=kde_type)\n",
    "\n",
    "        kde_mix = gaussian_kde(np.apply_along_axis(kde_inner_fun, 0, preds[target == 1]), bw_mix)\n",
    "        kde_pos = gaussian_kde(np.apply_along_axis(kde_inner_fun, 0, preds[target == 0]), bw_pos)\n",
    "\n",
    "    elif kde_type == 'GMM':\n",
    "        if tune:\n",
    "            n_gauss_mix = maximize_log_likelihood(preds[target == 1], kde_inner_fun, kde_outer_fun, kde_type=kde_type)\n",
    "            n_gauss_pos = maximize_log_likelihood(preds[target == 0], kde_inner_fun, kde_outer_fun, kde_type=kde_type)\n",
    "\n",
    "        GMM_mix = GaussianMixture(n_gauss_mix, covariance_type='spherical').fit(\n",
    "            np.apply_along_axis(kde_inner_fun, 0, preds[target == 1]).reshape(-1, 1))\n",
    "        GMM_pos = GaussianMixture(n_gauss_pos, covariance_type='spherical').fit(\n",
    "            np.apply_along_axis(kde_inner_fun, 0, preds[target == 0]).reshape(-1, 1))\n",
    "\n",
    "        kde_mix = lambda x: np.exp(GMM_mix.score_samples(x.reshape(-1, 1)))\n",
    "        kde_pos = lambda x: np.exp(GMM_pos.score_samples(x.reshape(-1, 1)))\n",
    "\n",
    "    elif kde_type == 'hist':\n",
    "        if tune:\n",
    "            bins_mix = maximize_log_likelihood(preds[target == 1], kde_inner_fun, lambda kde, x: kde(x),\n",
    "                                               kde_type=kde_type)\n",
    "            bins_pos = maximize_log_likelihood(preds[target == 0], kde_inner_fun, lambda kde, x: kde(x),\n",
    "                                               kde_type=kde_type)\n",
    "        bars_mix = np.histogram(preds[target == 1], bins=bins_mix, range=(0, 1), density=True)[0]\n",
    "        bars_pos = np.histogram(preds[target == 0], bins=bins_pos, range=(0, 1), density=True)[0]\n",
    "\n",
    "        kde_mix = lambda x: bars_mix[np.clip((x // (1 / bins_mix)).astype(int), 0, bins_mix-1)]\n",
    "        kde_pos = lambda x: bars_pos[np.clip((x // (1 / bins_pos)).astype(int), 0, bins_pos-1)]\n",
    "        kde_outer_fun = lambda kde, x: kde(x)\n",
    "\n",
    "    # sorting to relax and impose monotonicity\n",
    "    sorted_mixed = np.sort(preds[target == 1])\n",
    "\n",
    "    diff = np.apply_along_axis(lambda x: kde_outer_fun(kde_pos, x) / (kde_outer_fun(kde_mix, x) + 10 ** -5), axis=0,\n",
    "                               arr=sorted_mixed)\n",
    "    diff[diff > 50] = 50\n",
    "    diff = rolling_apply(diff, 5)\n",
    "    diff = np.append(\n",
    "        np.flip(np.maximum.accumulate(np.flip(diff[sorted_mixed <= threshold], axis=0)), axis=0),\n",
    "        diff[sorted_mixed > threshold])\n",
    "    diff = rolling_apply(diff, k_neighbours)\n",
    "\n",
    "    if MT:\n",
    "        MTrends = MonotonizingTrends(MT_coef=MT_coef)\n",
    "        diff = np.flip(np.array(MTrends.monotonize_array(np.flip(diff, axis=0), reset=True, decay_MT_coef=decay_MT_coef)), axis=0)\n",
    "\n",
    "    diff.sort()\n",
    "    diff = np.flip(diff, axis=0)\n",
    "\n",
    "    # desorting\n",
    "    diff = diff[np.argsort(np.argsort(preds[target == 1]))]\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "def estimate_diff_bayes(means, variances, target, threshold=None, k_neighbours=None):\n",
    "    if threshold == 'mid':\n",
    "        threshold = means[target == 1].mean() / 2 + means[target == 0].mean() / 2\n",
    "    elif (threshold == 'low') or (threshold is None):\n",
    "        threshold = means[target == 0].mean()\n",
    "    elif threshold == 'high':\n",
    "        threshold = means[target == 1].mean()\n",
    "\n",
    "    if k_neighbours is None:\n",
    "        k_neighbours = int(means[target == 1].shape[0] // 20)\n",
    "\n",
    "    n_mix = means[target == 1].shape[0]\n",
    "    GMM_mix = GaussianMixtureNoFit(n_mix, covariance_type='spherical', max_iter=1, n_init=1,\n",
    "                                   weights_init=np.ones(n_mix) / n_mix,\n",
    "                                   means_init=means[target == 1].reshape(-1, 1),\n",
    "                                   precisions_init=1 / variances[target == 1]).fit(\n",
    "        means[target == 1].reshape(-1, 1))\n",
    "    kde_mix = lambda x: np.exp(GMM_mix.score_samples(x))\n",
    "\n",
    "    n_pos = means[target == 0].shape[0]\n",
    "    GMM_pos = GaussianMixtureNoFit(n_pos, covariance_type='spherical', max_iter=1, n_init=1,\n",
    "                                   weights_init=np.ones(n_pos) / n_pos,\n",
    "                                   means_init=means[target == 0].reshape(-1, 1),\n",
    "                                   precisions_init=1 / variances[target == 0]).fit(\n",
    "        means[target == 0].reshape(-1, 1))\n",
    "    kde_pos = lambda x: np.exp(GMM_pos.score_samples(x))\n",
    "\n",
    "    sorted_means = np.sort(means[target == 1])\n",
    "    # diff = np.array(kde_pos(sorted_means.reshape(-1, 1)) / kde_mix(sorted_means.reshape(-1, 1)))\n",
    "    diff = np.array([])\n",
    "    for i in range(int(np.ceil(len(sorted_means) / 1000))):\n",
    "        current = sorted_means[i * 1000: min((i + 1) * 1000, len(sorted_means))]\n",
    "        diff = np.append(diff, kde_pos(current.reshape(-1, 1)) / kde_mix(current.reshape(-1, 1)))\n",
    "    diff[diff > 50] = 50\n",
    "\n",
    "    diff = rolling_apply(diff, k_neighbours)\n",
    "    diff = np.append(np.flip(np.maximum.accumulate(np.flip(diff[sorted_means <= threshold], axis=0)), axis=0),\n",
    "                     diff[sorted_means > threshold])\n",
    "\n",
    "    diff = diff[np.argsort(np.argsort(means[target == 1]))]\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "def estimate_poster_dedpul(diff, alpha=None, quantile=0.05, alpha_as_mean_poster=False, max_it=100, **kwargs):\n",
    "    \"\"\"\n",
    "    Estimates posteriors and priors alpha (if not provided) of N in U with dedpul method\n",
    "    :param diff: difference of densities f_p / f_u for the sample U, np.array (n,), output of estimate_diff()\n",
    "    :param alpha: priors, share of N in U (estimated if None)\n",
    "    :param quantile: if alpha is None, relaxation of the estimate of alpha;\n",
    "        here alpha is estimaeted as infinum, and low quantile is its relaxed version;\n",
    "        share of posteriors probabilities that we allow to be negative (with the following zeroing-out)\n",
    "    :param kwargs: dummy\n",
    "\n",
    "    :return: tuple (alpha, poster), e.g. (priors, posteriors) of N in U for the U sample, represented by diff\n",
    "    \"\"\"\n",
    "    if alpha_as_mean_poster and (alpha is not None):\n",
    "        poster = 1 - diff * (1 - alpha)\n",
    "        poster[poster < 0] = 0\n",
    "        cur_alpha = np.mean(poster)\n",
    "        if cur_alpha < alpha:\n",
    "            left_border = alpha\n",
    "            right_border = 1\n",
    "        else:\n",
    "            left_border = 0\n",
    "            right_border = alpha\n",
    "\n",
    "            poster_zero = 1 - diff\n",
    "            poster_zero[poster_zero < 0] = 0\n",
    "            if np.mean(poster_zero) > alpha:\n",
    "                left_border = -50\n",
    "                right_border = 0\n",
    "                # return 0, poster_zero\n",
    "        it = 0\n",
    "        try_alpha = cur_alpha\n",
    "        while (abs(cur_alpha - alpha) > kwargs.get('tol', 10**-5)) and (it < max_it):\n",
    "            try_alpha = (left_border + (right_border - left_border) / 2)\n",
    "            poster = 1 - diff * (1 - try_alpha)\n",
    "            poster[poster < 0] = 0\n",
    "            cur_alpha = np.mean(poster)\n",
    "            if cur_alpha > alpha:\n",
    "                right_border = try_alpha\n",
    "            else:\n",
    "                left_border = try_alpha\n",
    "            it += 1\n",
    "        alpha = try_alpha\n",
    "        if it >= max_it:\n",
    "            print('Exceeded maximal number of iterations in finding mean_poster=alpha')\n",
    "    else:\n",
    "        if alpha is None:\n",
    "            alpha = 1 - 1 / max(np.quantile(diff, 1 - quantile, interpolation='higher'), 1)\n",
    "        poster = 1 - diff * (1 - alpha)\n",
    "        poster[poster < 0] = 0\n",
    "    return alpha, poster\n",
    "\n",
    "\n",
    "def estimate_poster_en(preds, target, alpha=None, estimator='e1', quantile=0.05, **kwargs):\n",
    "    \"\"\"\n",
    "    Estimates posteriors and priors alpha (if not provided) of N in U with en [Elkan-Noto, 2008] method\n",
    "    :param preds: predictions of classifier, np.array with shape (n,)\n",
    "    :param target: binary vector, 0 if positive, 1 if unlabeled, np.array with shape (n,)\n",
    "    :param alpha: priors, share of N in U (estimated if None)\n",
    "    :param estimator: 'e1' or 'e3' - from [Elkan-Noto, 2008]\n",
    "    :param quantile: if alpha is None and estimator is 'e3', relaxation of the estimate of alpha;\n",
    "        share of posteriors probabilities that we allow to be negative (with the following zeroing-out)\n",
    "    :param kwargs: dummy\n",
    "    :return: tuple (alpha, poster), e.g. (priors, posteriors) of N in U for the U sample preds[target == 1]\n",
    "    \"\"\"\n",
    "    if alpha is None:\n",
    "        if estimator == 'e1':\n",
    "            c = 1 - np.mean(preds[target == 0])\n",
    "            alpha = 1 - (1 - c) / c\n",
    "        elif estimator == 'e3':\n",
    "            # c = np.quantile(1 - preds, 0.95)\n",
    "            alpha = 1 - min(np.quantile(preds / (1 - preds), quantile, interpolation='lower'), 1)\n",
    "        # alpha = 1 - (1 - c) / c\n",
    "        alpha = max(alpha, 0)\n",
    "    poster = 1 - (1 - alpha) * (1 - preds[target == 1]) / preds[target == 1]\n",
    "    poster[poster < 0] = 0\n",
    "    return alpha, poster\n",
    "\n",
    "\n",
    "def estimate_poster_em(diff=None, preds=None, target=None, mode='dedpul', converge=True, tol=10**-5,\n",
    "                       max_iterations=1000, nonconverge=True, step=0.001, max_diff=0.05, plot=False, disp=False,\n",
    "                       alpha=None, alpha_as_mean_poster=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Performs Expectation-Maximization to estimate posteriors and priors alpha (if not provided) of N in U\n",
    "        with either of 'en' or 'dedpul' methods; both 'converge' and 'nonconverge' are recommended to be set True for\n",
    "        better estimate\n",
    "    :param diff: difference of densities f_p/f_u for the sample U, np.array (n,), output of estimate_diff()\n",
    "    :param preds: predictions of classifier, np.array with shape (n,)\n",
    "    :param target: binary vector, 0 if positive, 1 if unlabeled, np.array with shape (n,)\n",
    "    :param mode: 'dedpul' or 'en'; if 'dedpul', diff needs to be provided; if 'en', preds and target need to be provided\n",
    "    :param converge: True or False; True if convergence estimate should be computed\n",
    "    :param tol: tolerance of error between priors and mean posteriors, indicator of convergence\n",
    "    :param max_iterations: if exceeded, search of converged alpha stops even if tol is not reached\n",
    "    :param nonconverge: True or False; True if non-convergence estimate should be computed\n",
    "    :param step: gap between points of the [0, 1, step] gird to choose best alpha from\n",
    "    :param max_diff: alpha with difference of mean posteriors and priors bigger than max_diff cannot be chosen;\n",
    "        an heuristic to choose bigger alpha\n",
    "    :param plot: True or False, if True - plots ([0, 1, grid], mean posteriors - alpha) and\n",
    "        ([0, 1, grid], second lag of (mean posteriors - alpha))\n",
    "    :param disp: True or False, if True - displays if the algorithm didn't converge\n",
    "    :param alpha: proportions of N in U; is estimated if None\n",
    "    :return: tuple (alpha, poster), e.g. (priors, posteriors) of N in U for the U sample\n",
    "    \"\"\"\n",
    "    assert converge + nonconverge, \"At least one of 'converge' and 'nonconverge' has to be set to 'True'\"\n",
    "\n",
    "    if alpha is not None:\n",
    "        if mode == 'dedpul':\n",
    "            alpha, poster = estimate_poster_dedpul(diff, alpha=alpha, alpha_as_mean_poster=alpha_as_mean_poster, tol=tol, **kwargs)\n",
    "        elif mode == 'en':\n",
    "            _, poster = estimate_poster_en(preds, target, alpha=alpha, **kwargs)\n",
    "        return alpha, poster\n",
    "\n",
    "    # if converge:\n",
    "    alpha_converge = 0\n",
    "    for i in range(max_iterations):\n",
    "\n",
    "        if mode.endswith('dedpul'):\n",
    "            _, poster_converge = estimate_poster_dedpul(diff, alpha=alpha_converge, **kwargs)\n",
    "        elif mode == 'en':\n",
    "            _, poster_converge = estimate_poster_en(preds, target, alpha=alpha_converge, **kwargs)\n",
    "\n",
    "        mean_poster = np.mean(poster_converge)\n",
    "        error = mean_poster - alpha_converge\n",
    "\n",
    "        if np.abs(error) < tol:\n",
    "            break\n",
    "        if np.min(poster_converge) > 0:\n",
    "            break\n",
    "        alpha_converge = mean_poster\n",
    "\n",
    "    if disp:\n",
    "        if i >= max_iterations - 1:\n",
    "            print('max iterations exceeded')\n",
    "\n",
    "    # if nonconverge:\n",
    "\n",
    "    errors = np.array([])\n",
    "    for alpha_nonconverge in np.arange(0, 1, step):\n",
    "\n",
    "        if mode.endswith('dedpul'):\n",
    "            _, poster_nonconverge = estimate_poster_dedpul(diff, alpha=alpha_nonconverge, **kwargs)\n",
    "        elif mode == 'en':\n",
    "            _, poster_nonconverge = estimate_poster_en(preds, target, alpha=alpha_nonconverge, **kwargs)\n",
    "        errors = np.append(errors, np.mean(poster_nonconverge) - alpha_nonconverge)\n",
    "\n",
    "    idx = np.argmax(np.diff(np.diff(errors))[errors[1: -1] < max_diff])\n",
    "    alpha_nonconverge = np.arange(0, 1, step)[1: -1][errors[1: -1] < max_diff][idx]\n",
    "\n",
    "    if plot:\n",
    "        fig, axs = plt.subplots(2, 1, sharex=False, sharey=False, figsize=(6, 10))\n",
    "        axs[0].plot(np.arange(0, 1, step), errors)\n",
    "        axs[1].plot(np.arange(0, 1, step)[1: -1], np.diff(np.diff(errors)))\n",
    "\n",
    "    # if converge and not nonconverge:y77\n",
    "    #     return alpha_converge, poster_converge\n",
    "\n",
    "    if ((alpha_nonconverge >= alpha_converge) or#converge and nonconverge and\n",
    "        (((errors < 0).sum() > 1) and (alpha_converge < 1 - step))):\n",
    "        return alpha_converge, poster_converge\n",
    "\n",
    "    elif nonconverge:\n",
    "        if mode == 'dedpul':\n",
    "            _, poster_nonconverge = estimate_poster_dedpul(diff, alpha=alpha_nonconverge, **kwargs)\n",
    "        elif mode == 'en':\n",
    "            _, poster_nonconverge = estimate_poster_en(preds, target, alpha=alpha_nonconverge, **kwargs)\n",
    "\n",
    "        if disp:\n",
    "            print('didn\\'t converge')\n",
    "        return alpha_nonconverge, poster_nonconverge\n",
    "        # return np.mean(poster_nonconverge), poster_nonconverge\n",
    "\n",
    "    else:\n",
    "        if disp:\n",
    "            print('didn\\'t converge')\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = estimate_poster_cv(X_train,y_train, estimator='ntc_methods', alpha=None,\n",
    "                                         estimate_poster_options={'disp': False},\n",
    "                                         estimate_diff_options={})\n",
    "\n",
    "for key,value in d.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52037e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "#prior\n",
    "bst.fit(X_train, y_train)\n",
    "alpha_used = 1.0 - d['dedpul'][0] \n",
    "ratio = 1.0*(len(pos_X_train)+alpha_used*len(un_X_train))/len(pos_X_train)\n",
    "pre_probs = bst.predict_proba(train)[:,1]\n",
    "#post-processing\n",
    "preds = pre_probs*ratio\n",
    "predictions = pd.Series([1 if value>=0.5 else 0 for value in preds]) \n",
    "G_new = copy.deepcopy(G0) \n",
    "\n",
    "fp_X_1 = train_1[(target==0)&(predictions==1)]\n",
    "print(len(fp_X_1))\n",
    "\n",
    "for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\")\n",
    "#\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity \n",
    "\n",
    "preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "preds = preds*ratio\n",
    "predictions = [1 if value>=0.5 else 0 for value in preds] \n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0)) #recall_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c699731",
   "metadata": {},
   "source": [
    "## 7.3 DEDPUL + CVIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5df35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "bst = copy.deepcopy(xgb_normal)\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    ratio,_ = estimate_poster_cv(X_test,y_test, estimator='dedpul', alpha=None,\n",
    "                                             estimate_poster_options={'disp': False},\n",
    "                                             estimate_diff_options={})\n",
    "    alpha_used = 1.0-ratio\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = alpha_default\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and drop the suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_tmp = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_X_1 = train_1[target==0]\n",
    "un_X = train[target==0]\n",
    "un = samples_3[target==0]\n",
    "pos_X_1 = train_1[target>0]\n",
    "pos_X = train[target>0]\n",
    "\n",
    "preds = bst.predict_proba(un_X)[:,1]\n",
    "fp = un[preds>=0.4]\n",
    "\n",
    "G_new = copy.deepcopy(G0) \n",
    "for index, row in fp[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9848d",
   "metadata": {},
   "source": [
    "## 7.4 EN + CVIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db602c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_default = 0.8 \n",
    "epochs = 20\n",
    "thr = 0.4\n",
    "if_pu = True\n",
    "bst = copy.deepcopy(xgb_normal)\n",
    "\n",
    "#after warm start\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    pos_probs = np.array(bst.predict_proba(pos_X_test)[:,1])\n",
    "    unlabeled_probs = np.array(bst.predict_proba(un_X_test)[:,1])\n",
    "    unlabeled_targets = np.array([1 if i>=thr else 0 for i in unlabeled_probs])\n",
    "\n",
    "    #step1:MPE\n",
    "    ratio,_ = estimate_poster_cv(X_test,y_test, estimator='em_en', alpha=None,\n",
    "                                             estimate_poster_options={'disp': False},\n",
    "                                             estimate_diff_options={})\n",
    "    alpha_used = 1.0-ratio\n",
    "    if alpha_used >=1:\n",
    "        alpha_used = alpha_default\n",
    "    \n",
    "    #step2: PvN training\n",
    "    #select the reliable negative samples and drop the suspicious positive samples\n",
    "    keep_samples = rank_inputs(bst, un_X_train, alpha_used)\n",
    "    unlabeled_new = un_X_train[keep_samples == 1]\n",
    "    pos_new = un_X_train[keep_samples ==0]\n",
    "    \n",
    "    X_train_new = pd.concat([pos_X_train,unlabeled_new],axis=0)\n",
    "    y_train_new = pd.DataFrame([1]*(len(pos_X_train)+[0]*len(unlabeled_new)).iloc[:,0]\n",
    "\n",
    "    bst.fit(X_train_new,y_train_new)\n",
    "   \n",
    "    \n",
    "    print(\"epoch{}, alpha = {}\\n\".format(epoch,alpha_used))\n",
    "    train_preds = bst.predict_proba(X_train)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "    train_preds = bst.predict_proba(X_train_new)[:,1]\n",
    "    train_predictions = [1 if value>=thr else 0 for value in train_preds]\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "    train_precision = precision_score(y_train_new, train_predictions)\n",
    "    train_recall = recall_score(y_train_new, train_predictions)\n",
    "    train_f1 = f1_score(y_train_new, train_predictions)\n",
    "    train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "    print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "    print (\"Train f1: %.4f\" % (train_f1))\n",
    "    print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(X_test)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds] \n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, predictions)\n",
    "    test_precision = precision_score(y_test, predictions)\n",
    "    test_recall = recall_score(y_test, predictions)\n",
    "    test_f1=f1_score(y_test, predictions)\n",
    "    test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "    # make prediction\n",
    "    preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "    predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "    new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "    print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #new recall\n",
    "    \n",
    "    pos_X_test = X_test[y_test==1]\n",
    "    un_X_test = X_test[y_test==0]\n",
    "    keep_samples_test = rank_inputs(bst, un_X_test, alpha_used)\n",
    "    unlabeled_new_test = un_X_test[keep_samples_test == 1]\n",
    "    pos_new_test = un_X_test[keep_samples_test ==0]\n",
    "    \n",
    "    X_test_new = pd.concat([pos_X_test,pos_new_test,unlabeled_new_test],axis=0)\n",
    "    y_test_new = pd.DataFrame([1]*(len(pos_X_test)+len(pos_new_test))+[0]*len(unlabeled_new_test)).iloc[:,0]\n",
    "    \n",
    "    preds = bst.predict_proba(X_test_new)[:,1]\n",
    "    predictions = [1 if value>=thr else 0 for value in preds]\n",
    "    test_accuracy = accuracy_score(y_test_new, predictions)\n",
    "    test_precision = precision_score(y_test_new, predictions)\n",
    "    test_recall = recall_score(y_test_new, predictions)\n",
    "    test_f1=f1_score(y_test_new, predictions)\n",
    "    test_auc=roc_auc_score(y_test_new,preds)\n",
    "    print(\"New positive samples added:\")\n",
    "    print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "    print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "    print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "    print (\"Test f1: %.4f\" % (test_f1))\n",
    "    print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "xgb_tmp = copy.deepcopy(bst)\n",
    "#feature importance\n",
    "plot_importance(xgb_tmp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7533bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_X_1 = train_1[target==0]\n",
    "un_X = train[target==0]\n",
    "un = samples_3[target==0]\n",
    "pos_X_1 = train_1[target>0]\n",
    "pos_X = train[target>0]\n",
    "\n",
    "preds = bst.predict_proba(un_X)[:,1]\n",
    "fp = un[preds>=0.4]\n",
    "\n",
    "G_new = copy.deepcopy(G0) \n",
    "for index, row in fp[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa769cc",
   "metadata": {},
   "source": [
    "## 7.5 C-CRE with GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf185b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the GMM\n",
    "gm = GaussianMixture(n_components=8, random_state=0,covariance_type='diag')\n",
    "y_0 = gm.fit_predict(samples)\n",
    "y_pred = gm.predict_proba(samples)\n",
    "y_pred = y_pred[:,4]+y_pred[:,5] #y_pred[:,0]+y_pred[:,1]+y_pred[:,2]\n",
    "y = (y_pred>=thr).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = []\n",
    "x2 = []\n",
    "print(len(X_train))\n",
    "print(gm.weights_)\n",
    "for i in range(len(gm.weights_)):\n",
    "    part = target[y_0==i]\n",
    "    print(\"cluster_\"+str(i)+\": \"+str(len(part)))\n",
    "    print(\"Positive Cnt\"+str(np.sum(part))+\" Ratio\"+str(1.0*np.sum(part)/len(part)))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb755759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y))\n",
    "test_accuracy = accuracy_score(target, y)\n",
    "test_precision = precision_score(target, y)\n",
    "test_recall = recall_score(target, y)\n",
    "test_f1 = f1_score(target, y)\n",
    "test_auc = roc_auc_score(target,y_pred)\n",
    "\n",
    "print(\"Whole Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Whole Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Whole Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Whole f1: %.4f\" % (test_f1))\n",
    "print (\"Test auc: %.4f\" % (test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mod = -0.5\n",
    "best_clf = None\n",
    "max_size = 0\n",
    "for beta in np.arange(0.1,0.2,0.01): #hypeparmetet tuning with high modulairty and size\n",
    "    un_probs = gm.predict_proba(un_X_train)[:,4]+gm.predict_proba(un_X_train)[:,5]\n",
    "    sorted_idx = np.argsort(un_probs)\n",
    "    u_size = len(sorted_idx)\n",
    "    keep_samples = np.ones_like(un_probs)\n",
    "    keep_samples[sorted_idx[int(beta*u_size):]] = 0\n",
    "    neg_X_train = un_X_train[keep_samples==1]\n",
    "    y_train_new = [1 for i in range(len(pos_X_train))]+[0 for i in range(len(neg_X_train))]\n",
    "    X_train_new = pd.concat([pos_X_train,neg_X_train])\n",
    "    \n",
    "    clf = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(neg_X_train)//len(pos_X_train)) #sklearn api\n",
    "    clf.fit(X_train_new, y_train_new)\n",
    "    \n",
    "    preds = clf.predict_proba(samples)[:,1]\n",
    "    predictions = pd.Series([1 if value>=thr else 0 for value in preds])\n",
    "    G_new = copy.deepcopy(G0) \n",
    "\n",
    "    fp_X_1 = train_1[(target==0)&(predictions==1)] \n",
    "\n",
    "    for index, row in fp_X_1[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "        G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "\n",
    "    print(G_new.number_of_nodes())\n",
    "    print(G_new.number_of_edges())\n",
    "    size = G_new.number_of_nodes()\n",
    "    \n",
    "    partition = community.best_partition(G_new) \n",
    "    print(\"partition ok\") \n",
    "    num_com = len(set(partition.values()))\n",
    "    aver_size = size/num_com\n",
    "    print(num_com)\n",
    "    if aver_size<2: #too much partition\n",
    "        continue\n",
    "        \n",
    "    mod = community.modularity(partition,G_new)\n",
    "    print(mod) #modularity\n",
    "    if (mod+0.01>best_mod and size>max_size) or mod>best_mod+0.01:\n",
    "        print(f\"The best parameter beta is updated: beta is {beta}.\")\n",
    "        best_mod = mod\n",
    "        best_clf = clf\n",
    "        max_size = max(max_size,size)\n",
    "        \n",
    "print(best_mod)\n",
    "xgb_gmm = copy.deepcopy(best_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = best_clf.predict_proba(X_train_new)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_new, train_predictions)\n",
    "train_precision = precision_score(y_train_new, train_predictions)\n",
    "train_recall = recall_score(y_train_new, train_predictions)\n",
    "train_f1 = f1_score(y_train_new, train_predictions)\n",
    "train_auc = roc_auc_score(y_train_new,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = best_clf.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = best_clf.predict_proba(new_pos_X)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))  #recall_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66953b",
   "metadata": {},
   "source": [
    "## 7.6 PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd08249",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train,y_train)\n",
    "\n",
    "#choose the best hyperparmeters (proportion of unlabeld samples to use), same way as C-CRE\n",
    "lamda1 = 1.0\n",
    "lamda2 = 0.3\n",
    "preds = bst.predict_proba(un_X_train)[:,1] \n",
    "fp_X_train = un_X_train[preds>=0.4]\n",
    "keep_samples = rank_inputs(bst, fp_X_train, lamda1)\n",
    "rp_X_train = fp_X_train[keep_samples ==0]\n",
    "tn_X_train = un_X_train[preds<0.4]\n",
    "keep_samples = rank_inputs(bst, tn_X_train, 1-lamda2)\n",
    "rn_X_train = tn_X_train[keep_samples ==0]\n",
    "\n",
    "X_train_new = pd.concat([pos_X_train,rp_X_train,rn_X_train],axis=0)\n",
    "y_train_new = pd.DataFrame([1]*(len(pos_X_train)+len(rp_X_train))+[0]*len(rn_X_train)).iloc[:,0]\n",
    "\n",
    "bst.fit(X_train_new,y_train_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20219c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ce4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_X_1 = train_1[target==0]\n",
    "un_X = train[target==0]\n",
    "un = samples_3[target==0]\n",
    "pos_X_1 = train_1[target>0]\n",
    "pos_X = train[target>0]\n",
    "\n",
    "preds = bst.predict_proba(un_X)[:,1]\n",
    "fp = un[preds>=0.4]\n",
    "\n",
    "G_new = copy.deepcopy(G0) \n",
    "for index, row in fp[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd249c2",
   "metadata": {},
   "source": [
    "## 7.7 PGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1fe7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train,y_train)\n",
    "\n",
    "preds = bst.predict_proba(un_X_train)[:,1] \n",
    "fp_X_train = un_X_train[preds>=0.4]\n",
    "# choose the reliable negative samples\n",
    "min_score = np.min(np.array(bst.predict_proba(pos_X_train)))\n",
    "print(min_score)\n",
    "rn_X_train = un_X_train[preds<min_score]\n",
    "\n",
    "X_train_new = pd.concat([pos_X_train,fp_X_train,rn_X_train],axis=0)\n",
    "y_train_new = pd.DataFrame([1]*(len(pos_X_train)+len(fp_X_train))+[0]*len(rn_X_train)).iloc[:,0]\n",
    "\n",
    "bst.fit(X_train_new,y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict_proba(new_pos_X)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] #0.4threshold\n",
    "new_test_recall = recall_score([1]*len(predictions), predictions)\n",
    "print (\"New Test Recall: %.2f%%\" % (new_test_recall * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ecf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_X_1 = train_1[target==0]\n",
    "un_X = train[target==0]\n",
    "un = samples_3[target==0]\n",
    "pos_X_1 = train_1[target>0]\n",
    "pos_X = train[target>0]\n",
    "\n",
    "preds = bst.predict_proba(un_X)[:,1]\n",
    "fp = un[preds>=0.4]\n",
    "\n",
    "G_new = copy.deepcopy(G0) \n",
    "for index, row in fp[['roleid_src','roleid_dst','trade_n_times_mean']].iterrows():\n",
    "    G_new.add_edge(row['roleid_src'],row['roleid_dst'],weight=row['trade_n_times_mean'])\n",
    "    \n",
    "print(G_new.number_of_nodes())\n",
    "print(G_new.number_of_edges())\n",
    "partition = community.best_partition(G_new) \n",
    "print(\"partition ok\") \n",
    "\n",
    "size = len(set(partition.values())) #number of communities\n",
    "print(size)\n",
    "mod = community.modularity(partition,G_new)\n",
    "print(mod) #modularity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e50593f",
   "metadata": {},
   "source": [
    "# 8. Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples = samples_2[samples_2['label']==1]\n",
    "unlabeled_samples = samples_2[samples_2['label']==0]\n",
    "profile_51 = profile[profile['ds']=='2021-05-01']\n",
    "print(profile_51.describe())\n",
    "\n",
    "#draw two main trading features\n",
    "font_size_1 = 25\n",
    "font_size_2 = 20\n",
    "sns.set(style='ticks',context='notebook',font_scale=1.2)#\n",
    "plt.scatter(pos_samples['diff_price_mean'],pos_samples['ts_between_mean'],label='Positive',s=2,c='r')\n",
    "plt.scatter(unlabeled_samples.head(5000)['diff_price_mean'],unlabeled_samples.head(5000)['ts_between_mean'],label='Unlabeled',s=2,c='g')\n",
    "plt.xticks(fontsize = font_size_2)\n",
    "plt.yticks(fontsize = font_size_2)\n",
    "plt.legend(fontsize = font_size_1)\n",
    "plt.xlabel(\"Mean of Item Price Gap\",fontsize = font_size_1)\n",
    "plt.ylabel(\"Mean of Interval (second)\",fontsize = font_size_1)\n",
    "plt.savefig(\"./pictures_tmp/labels_x.pdf\",bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206435d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the central node of the biggest community\n",
    "target_id = '7bbd84581e618d1d3cecc2ea25410254'\n",
    "tmp_1 = samples_2[samples_2['roleid_src']==target_id]\n",
    "tmp_2 = samples_2[samples_2['roleid_dst']==target_id]\n",
    "tp_fp = pd.read_csv('data_gnn/test_fp_tp_classes_5.csv')[['Id']]\n",
    "tmp_1 = tp_fp.merge(tmp_1,left_on='Id',right_on='roleid_dst')\n",
    "tmp_2 = tp_fp.merge(tmp_2,left_on='Id',right_on='roleid_src')\n",
    "print(tmp_1)\n",
    "print(tmp_2)\n",
    "bins=np.arange(-10000,2000,100)\n",
    "plt.hist(tmp_1['net_money_y_mean'],bins,color='b',alpha=0.5)\n",
    "sns.distplot(tmp_1['net_money_y_mean'],color='b',kde=False, norm_hist=False)\n",
    "plt.show()\n",
    "sns.distplot(tmp_2['net_money_x_mean'],color='b',kde=False, norm_hist=False)\n",
    "plt.show()\n",
    "sns.distplot(node_money['net_money'],color='b',kde=False, norm_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the role of edge nodes using player profile (3 types)\n",
    "sns.set(style='ticks',context='notebook',font_scale=1.2)\n",
    "i = 1\n",
    "bins_dict = {'level1':np.arange(-1,1,0.01),'score2':np.arange(-1,1,0.02),'online_time':np.arange(0,86400,1000)}\n",
    "font_size_1 = 25\n",
    "font_size_2 = 20\n",
    "#for col in ['level1','score2','online_time']:\n",
    "for col in ['score2','online_time']:\n",
    "    bins = bins_dict[col]\n",
    "\n",
    "    plt.hist(profile_51[col],bins,color='g',alpha=0.5)\n",
    "    if col=='online_time':\n",
    "        plt.xlabel('Weekly Online Time (second)',fontsize = font_size_1)\n",
    "    elif col=='score2':\n",
    "        plt.xlabel('Character score',fontsize = font_size_1)\n",
    "    plt.ylabel('Frequency',fontsize = font_size_1)\n",
    "    plt.xticks(fontsize = font_size_2)\n",
    "    plt.yticks(fontsize = font_size_2)\n",
    "    plt.legend([\"All Players\"],fontsize = font_size_1)\n",
    "    plt.savefig(\"./pictures_tmp/profile_\"+str(i)+\".pdf\",bbox_inches = 'tight')\n",
    "    i += 1\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(tmp_1[col+'_y_mean'],bins,color='b',alpha=0.5)\n",
    "    if col=='online_time':\n",
    "        plt.xlabel('Weekly Online Time (second)',fontsize = font_size_1)\n",
    "    elif col=='score2':\n",
    "        plt.xlabel('Character score',fontsize = font_size_1)\n",
    "    plt.ylabel('Frequency',fontsize = font_size_1)\n",
    "    plt.xticks(fontsize = font_size_2)\n",
    "    plt.yticks(fontsize = font_size_2)\n",
    "    plt.legend([\"Profitable Edge Players\"],fontsize = font_size_1)\n",
    "    plt.savefig(\"./pictures_tmp/profile_\"+str(i)+\".pdf\",bbox_inches = 'tight')\n",
    "    i += 1\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(tmp_2[col+'_x_mean'],bins,color='r',alpha=0.5)\n",
    "    if col=='online_time':\n",
    "        plt.xlabel('Weekly Online Time (second)',fontsize = font_size_1)\n",
    "    elif col=='score2':\n",
    "        plt.xlabel('Character score',fontsize = font_size_1)\n",
    "    plt.ylabel('Frequency',fontsize = font_size_1)\n",
    "    plt.xticks(fontsize = font_size_2)\n",
    "    plt.yticks(fontsize = font_size_2)\n",
    "    plt.legend([\"Losing Edge Players\"],fontsize = font_size_1)\n",
    "    plt.savefig(\"./pictures_tmp/profile_\"+str(i)+\".pdf\",bbox_inches = 'tight')\n",
    "    i += 1\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
