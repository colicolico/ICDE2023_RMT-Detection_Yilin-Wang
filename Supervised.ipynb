{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de6554d",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1005477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta,date,datetime\n",
    "import copy\n",
    "from scipy import stats\n",
    "import math\n",
    "import collections\n",
    "import importlib\n",
    "\n",
    "import sklearn\n",
    "from sklearn import manifold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "import dgl\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # font family set\n",
    "plt.rcParams['axes.unicode_minus'] = False  # for minus display\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style(style='ticks') #set background\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "%config InlineBackend.figure_format = 'svg' #show svg pictures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df42caf",
   "metadata": {},
   "source": [
    "# 2.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_2 = pd.read_csv('./data_gnn/samples_2.csv')\n",
    "samples_2 = samples_2.drop(columns=['level1_x_mean', 'level2_x_mean',\n",
    "       'level3_x_mean', 'level4_x_mean', 'score1_x_mean', 'score2_x_mean',\n",
    "       'exp1_x_mean', 'exp2_x_mean', 'exp3_x_mean', 'online_time_x_mean',\n",
    "       'level1_y_mean', 'level2_y_mean', 'level3_y_mean', 'level4_y_mean',\n",
    "       'score1_y_mean', 'score2_y_mean', 'exp1_y_mean', 'exp2_y_mean',\n",
    "       'exp3_y_mean', 'online_time_y_mean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = samples_2.iloc[:,2:-2]\n",
    "target = samples_2.iloc[:,-2]\n",
    "scaler = RobustScaler() #normalize for robust\n",
    "samples = scaler.fit_transform(train)\n",
    "samples = pd.DataFrame(samples,index=train.index,columns=train.columns) \n",
    "samples.fillna(samples.mean(),inplace=True)\n",
    "train_1 = pd.concat([samples_2.iloc[:,0:2],samples],axis=1)  #with role IDs\n",
    "\n",
    "X_train_1, X_test_1, y_train, y_test = train_test_split(train_1, target, test_size = 0.2, random_state = 7)\n",
    "X_train = X_train_1.iloc[:,2:]\n",
    "X_test = X_test_1.iloc[:,2:]\n",
    "id_train = X_train_1.iloc[:,0:2]\n",
    "id_test = X_test_1.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X_train = X_train[y_train==1]\n",
    "pos_X_train_1 = X_train_1[y_train==1] #with role IDs\n",
    "un_X_train = X_train[y_train==0]\n",
    "un_X_train_1 = X_train_1[y_train==0] #with role IDs\n",
    "pos_X_test = X_test[y_test==1]\n",
    "pos_X_test_1 = X_test_1[y_test==1]\n",
    "un_X_test = X_test[y_test==0]\n",
    "un_X_test_1 = X_test_1[y_test==0]\n",
    "\n",
    "print(pos_X_train.shape)\n",
    "print(pos_X_test.shape)\n",
    "print(un_X_train.shape)\n",
    "print(un_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eefdab9",
   "metadata": {},
   "source": [
    "# 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier(max_depth=6,min_child_weight=2,learning_rate=0.01, n_estimators=100, \n",
    "                   objective='binary:logistic',scale_pos_weight=len(un_X_train)//len(pos_X_train)) #sklearn api\n",
    "\n",
    "\n",
    "bst.fit(X_train, y_train)\n",
    "xgb_normal = copy.deepcopy(bst)\n",
    "\n",
    "train_preds = bst.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))\n",
    "\n",
    "#feature importance\n",
    "plot_importance(xgb_normal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131354f",
   "metadata": {},
   "source": [
    "# 4. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeee249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for training (torch)\n",
    "class MyDatasets(Dataset):\n",
    "\n",
    "    def __init__(self,x,y): #numpy to tensor\n",
    "        self.x = torch.from_numpy(x.values)\n",
    "        self.y = torch.from_numpy(y.values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index],self.y[index] #,self.ids[index,:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "#DataLoader for training (torch)\n",
    "train_loader = DataLoader(MyDatasets(X_train,y_train), batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(MyDatasets(X_test,y_test), batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b551833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the net(MLP) architecture\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,output_dim):\n",
    "\n",
    "        super(Net,self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.out_layer = nn.Linear(hidden_dim,output_dim)\n",
    "        self.hidden_dict = collections.OrderedDict()\n",
    "        for i in range(num_layers):\n",
    "            self.hidden_dict['fc'+str(i+1)] = nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.hidden_layers = nn.Sequential(self.hidden_dict)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "        out = F.softmax(self.out_layer(x),dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device,train_loader, myloss, optimizer, epoch):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (train_x, train_y) in enumerate(train_loader):\n",
    "        train_x = Variable(train_x).to(device)\n",
    "        train_y = Variable(train_y).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = myloss(output, train_y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx%10 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tloss: {:.6f}'.format(\n",
    "                epoch, batch_idx*len(train_x), len(train_loader.dataset),loss.data.cpu().numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #to gpu if available\n",
    "net = Net(pos_X_train.shape[1],64,5,2)\n",
    "net = net.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net,device_ids=[0,1,2])\n",
    "print(net)  # net architecture\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001) \n",
    "weight = torch.DoubleTensor([len(pos_X_train),len(un_X_train)]).to(device)\n",
    "loss_func = nn.CrossEntropyLoss(weight=weight)  # the target label is NOT an one-hotted\n",
    "for epoch in range(50):  #training for a few epochs\n",
    "    \n",
    "    train(net,device,train_loader,loss_func,optimizer,epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gpu = copy.deepcopy(net)\n",
    "#net = net.to(\"cpu\")  #single-gpu\n",
    "net_cpu = net.module.to(\"cpu\")  #multi-gpu\n",
    "net_normal = copy.deepcopy(net_cpu)\n",
    "\n",
    "train_preds = net_cpu(torch.from_numpy(X_train.values))[:,1].detach().numpy()\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = net_cpu(torch.from_numpy(X_test.values))[:,1].detach().numpy()\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ba08d",
   "metadata": {},
   "source": [
    "# 5. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd371b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(class_weight='balanced')\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "train_preds = svc.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = svc.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f891fc",
   "metadata": {},
   "source": [
    "# 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f137bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced',min_samples_split=200,n_estimators=100)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "train_preds = rf.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = rf.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5ebca",
   "metadata": {},
   "source": [
    "# 7. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb10563",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()  #prior calculated by frequency\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "train_preds = nb.predict_proba(X_train)[:,1]\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = nb.predict_proba(X_test)[:,1]\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] #指定0.4为threshold\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c7bba",
   "metadata": {},
   "source": [
    "# 8. GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa02a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map node IDs to embeddings\n",
    "ids = np.unique(np.concatenate([samples_2['roleid_src'],samples_2['roleid_dst']]))\n",
    "id_dict = {}\n",
    "for i in range(len(ids)):\n",
    "    id_dict[ids[i]] = i\n",
    "id1 = torch.from_numpy(np.array([id_dict[x] for x in samples_2['roleid_src']]))\n",
    "id2 = torch.from_numpy(np.array([id_dict[x] for x in samples_2['roleid_dst']]))\n",
    "\n",
    "input_size = 8\n",
    "features = torch.randn(len(ids),input_size)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "features = features.to(device)\n",
    "\n",
    "# consturct the graph using trade amount/frequency\n",
    "G = dgl.DGLGraph()\n",
    "#use RMT prediction score(also tried trade amount/trade frequency) as edge weight\n",
    "G.add_edges(id1,id2,data={'weight':torch.from_numpy(np.array(samples_2['trade_n_times_mean']))})\n",
    "#add self-loops with weight 1.0\n",
    "G.add_edges(g.nodes(), g.nodes(),data={'weight':torch.ones_like(g.nodes(),dtype=torch.float32)})\n",
    "G = G.to(device)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31504849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.g = g\n",
    "        # equation (1)\n",
    "        self.fc = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        # equation (2)\n",
    "        self.attn_fc = nn.Linear(2 * out_dim, 1, bias=False)\n",
    "        self.edge_fc1 = nn.Linear(9 , 32, bias=False)\n",
    "        self.edge_fc2 = nn.Linear(32,1,bias=False)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        # edge UDF for equation (2)\n",
    "        z2 = torch.cat([edges.src['z'], edges.dst['z']], dim=1)\n",
    "        a = self.attn_fc(z2)\n",
    "        b = self.edge_fc1(edges.data['feat'])\n",
    "        b = F.elu(b)\n",
    "        b = self.edge_fc2(b)\n",
    "        return {'e': F.leaky_relu(a)+F.leaky_relu(b)}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        # message UDF for equation (3) & (4)\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "\n",
    "    def reduce_func(self, nodes):\n",
    "        # reduce UDF for equation (3) & (4)\n",
    "        # equation (3)\n",
    "        alpha = F.softmax(nodes.mailbox['e'], dim=1)\n",
    "        # equation (4)\n",
    "        h = torch.sum(alpha * nodes.mailbox['z'], dim=1)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, h):\n",
    "        # equation (1)\n",
    "        z = self.fc(h)\n",
    "        self.g.ndata['z'] = z\n",
    "        # equation (2)\n",
    "        self.g.apply_edges(self.edge_attention)\n",
    "        # equation (3) & (4)\n",
    "        self.g.update_all(self.message_func, self.reduce_func)\n",
    "        return self.g.ndata.pop('h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4053a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, g, in_dim, out_dim, num_heads, merge='cat'):\n",
    "        super(MultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        for i in range(num_heads):\n",
    "            self.heads.append(GATLayer(g, in_dim, out_dim))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, h):\n",
    "        head_outs = [attn_head(h) for attn_head in self.heads]\n",
    "        if self.merge == 'cat':\n",
    "            # concat on the output feature dimension (dim=1)\n",
    "            return torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            # merge using average\n",
    "            return torch.mean(torch.stack(head_outs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf213e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = MultiHeadGATLayer(g, in_dim, hidden_dim, num_heads)\n",
    "        # Be aware that the input dimension is hidden_dim*num_heads since\n",
    "        # multiple head outputs are concatenated together. Also, only\n",
    "        # one attention head in the output layer.\n",
    "        self.layer2 = MultiHeadGATLayer(g, hidden_dim * num_heads, hidden_dim, 1)\n",
    "        self.fc = nn.Linear(in_features=hidden_dim,out_features=out_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = self.layer1(h)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(h)\n",
    "        h = F.sigmoid(self.fc(h))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #logits = model(graph, features).cpu()\n",
    "        logits = model(features).cpu()\n",
    "        logits = logits.squeeze(dim=-1) \n",
    "        logits = logits[mask].cpu()\n",
    "        labels = labels[mask].cpu()\n",
    "        indices = logits>=0.5\n",
    "        #_, indices = torch.max(logits, dim=1)\n",
    "        #correct = torch.sum(indices == labels)\n",
    "        return accuracy_score(labels,indices),roc_auc_score(labels,logits),f1_score(labels,indices),precision_score(labels,indices),recall_score(labels,indices)\n",
    "\t\t#return correct.item() * 1.0 / len(labels) #acc作为评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70154459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test\n",
    "model = GAT(G,in_dim=n_features,hidden_dim=32,out_dim=1,num_heads=2)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    # forward propagation by using all samples\n",
    "    logits = model(node_features)\n",
    "    logits = logits.squeeze(dim=-1) \n",
    "    # compute loss\n",
    "    loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([30]).to(device))(logits[train_mask],node_labels[train_mask].float())\n",
    "    # compute train/validation accuracy\n",
    "    train_acc,train_auc,train_f1,train_precision,train_recall=evaluate(model, G, node_features, node_labels, train_mask) \n",
    "    valid_acc,valid_auc,valid_f1,valid_precision,valid_recall= evaluate(model, G, node_features, node_labels, valid_mask) \n",
    "    print(\"epoch:\"+str(epoch)+\" train_acc:\"+str(train_acc)+\" train_auc:\"+str(train_auc)+\" train_f1:\"+str(train_f1)+\" train_precision:\"+str(train_precision)+\" train_recall:\"+str(train_recall))\n",
    "    print(\"epoch:\"+str(epoch)+\" valid_acc:\"+str(valid_acc)+\" valid_auc:\"+str(valid_auc)+\" valid_f1:\"+str(valid_f1)+\" valid_precision:\"+str(valid_precision)+\" valid_recall:\"+str(valid_recall))\n",
    "    # backward propagation\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb3c67",
   "metadata": {},
   "source": [
    "# 9. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c07bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tansaction logs\n",
    "samples_1 = pd.read_csv('./data_gnn/samples_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a425d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_size=16\n",
    "def get_sample(user_row):\n",
    "\n",
    "    #user_row = user_row[np.newaxis, ...]\n",
    "    l = len(user_row)\n",
    "    x = []\n",
    "    for row in user_row:\n",
    "        x.append(np.array(row))\n",
    "    x = np.array(x)\n",
    "    #padding the sequence for training\n",
    "    if l < windows_size:\n",
    "        return np.pad(x, [[0,windows_size-x.shape[0]], [0, 0]],constant_values=0)\n",
    "    elif l > windows_size:\n",
    "        return x[-windows_size:]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da999d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_samples=[]\n",
    "labels=[]\n",
    "cut_length=[]\n",
    "grouped_samples_1=samples_1[['roleid_src','roleid_dst','x','label']].groupby(['roleid_src','roleid_dst']) #这里后面测好了改回samples_2\n",
    "\n",
    "#organize the transaction sequences\n",
    "for (roleid_src,roleid_dst),group in grouped_samples_1:\n",
    "    length=len(group)\n",
    "    if length==1:\n",
    "        continue\n",
    "    else:\n",
    "        if np.sum(group['label'])>0:\n",
    "            labels.append(1) \n",
    "        else:\n",
    "            labels.append(0)\n",
    "        users_samples.append(get_sample(group['x']))\n",
    "        if length<=windows_size:\n",
    "            cut_length.append(length)\n",
    "        else:\n",
    "            cut_length.append(windows_size)\n",
    "\n",
    "print(len(labels))\n",
    "print(np.sum(labels))\n",
    "print(np.sum(labels)/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32527931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for training (torch)\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y,length):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #return self.x[index], torch.tensor(self.y[index],dtype=torch.float64),self.length[index]\n",
    "        return self.x[index], self.y[index],self.length[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d210ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "num_val = (int)(val_ratio*len(labels))\n",
    "print(num_val)\n",
    "\n",
    "x_train = users_samples[:-num_val]\n",
    "y_train = labels[:-num_val]\n",
    "l_train = cut_length[:-num_val]\n",
    "x_test = users_samples[-num_val:]\n",
    "y_test = labels[-num_val:]\n",
    "l_test = cut_length[-num_val:]\n",
    "\n",
    "#split the train_test dataset\n",
    "train_dataset = MyDataset(x_train,y_train,l_train)\n",
    "test_dataset = MyDataset(x_test,y_test,l_test)\n",
    "\n",
    "#Data Loader for training (torch)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_1(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=32, output_size=2):\n",
    "        super().__init__()\n",
    "\n",
    "        #LSTM+lienar\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.lstm = nn.LSTM(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "\n",
    "        x = self.linear_1(input_seq[0])\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        data_packed_input = pack_padded_sequence(input=x, lengths=input_seq[1], batch_first=True,enforce_sorted=False)\n",
    "        _, (h_t,_) = self.lstm(data_packed_input)\n",
    "        predictions = self.linear_2(h_t.squeeze(0)) #undirected ltsm\n",
    "        predictions = F.softmax(predictions,dim=-1)\n",
    "        return predictions #the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5111cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "embedding_size = 64\n",
    "hidden_size = 64\n",
    "log_interval = 100\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training\n",
    "def train_1(log_interval, model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target_0, lengths) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target_0,lengths = data.to(device), target_0.to(device), lengths.to(device)\n",
    "        output = model((data,lengths))\n",
    "        \n",
    "\n",
    "        target = target_0.unsqueeze(1)\n",
    "        target = torch.LongTensor(target)\n",
    "        target = torch.zeros(len(lengths),2).scatter_(1,target,1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader.dataset), loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "def test_1(model, device, data, target_0, lengths, criterion, train_string): #valid or test\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        data, target_0,lengths = data.to(device), target_0.to(device), lengths.to(device)\n",
    "        output = model((data,lengths)) \n",
    "\n",
    "        target = target_0.unsqueeze(1)\n",
    "        target = torch.LongTensor(target)\n",
    "        target = torch.zeros(len(lengths),2).scatter_(1,target,1)\n",
    "\n",
    "        train_loss = criterion(output, target).item()\n",
    "        train_preds = F.softmax(output,1)[:,1].detach().numpy() #logits\n",
    "        train_predictions = output.argmax(dim=1, keepdim=True).detach().numpy()\n",
    "        y_train = target_0.detach().numpy()\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        train_precision = precision_score(y_train, train_predictions)\n",
    "        train_recall = recall_score(y_train, train_predictions)\n",
    "        train_f1 = f1_score(y_train, train_predictions)\n",
    "        train_auc = roc_auc_score(y_train,train_preds)\n",
    "        \n",
    "        print(train_string +' set: Average loss: {:.4f}'.format(train_loss))\n",
    "        print(train_string + \" Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "        print(train_string +\" Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "        print(train_string +\" Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "        print(train_string +\" f1: %.4f\" % (train_f1))\n",
    "        print(train_string +\" AUC: %.4f\" % (train_auc))\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model and loss/optimizer\n",
    "model_1 = LSTM_1(input_size = len(users_samples[0][0])).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight = torch.FloatTensor([1,100]))\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = torch.optim.Adam(model_1.parameters())\n",
    "#,lr=0.001,betas=(0.9, 0.999),eps=1e-08,weight_decay=0,amsgrad=False)\n",
    "\n",
    "#training\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(epoch)\n",
    "    train_1(log_interval, model_1, device, train_loader, criterion, optimizer, epoch)\n",
    "    test_1(model_1, device, torch.tensor(x_train), torch.tensor(y_train), torch.tensor(l_train), criterion,\"Train\")\n",
    "    test_1(model_1, device, torch.tensor(x_test), torch.tensor(y_test), torch.tensor(l_test), criterion,\"Test\")\n",
    "\n",
    "torch.save(model_1.state_dict(), \"test_lstm.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdc1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_gpu = copy.deepcopy(model_1)\n",
    "#net = net.to(\"cpu\")  #single-gpu\n",
    "net_cpu = model_1.module.to(\"cpu\")  #multi-gpu\n",
    "net_normal = copy.deepcopy(net_cpu)\n",
    "\n",
    "train_preds = net_cpu(torch.from_numpy(x_train))[:,1].detach().numpy()\n",
    "train_predictions = [1 if value>=0.4 else 0 for value in train_preds]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "train_auc = roc_auc_score(y_train,train_preds)\n",
    "\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "print (\"Train Precision: %.2f%%\" % (train_precision * 100.0))\n",
    "print (\"Train Recall: %.2f%%\" % (train_recall * 100.0))\n",
    "print (\"Train f1: %.4f\" % (train_f1))\n",
    "print (\"Train AUC: %.4f\" % (train_auc))\n",
    "\n",
    "\n",
    "# make prediction\n",
    "preds = net_cpu(torch.from_numpy(x_test))[:,1].detach().numpy()\n",
    "predictions = [1 if value>=0.4 else 0 for value in preds] \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, predictions)\n",
    "test_precision = precision_score(y_test, predictions)\n",
    "test_recall = recall_score(y_test, predictions)\n",
    "test_f1=f1_score(y_test, predictions)\n",
    "test_auc=roc_auc_score(y_test,preds)\n",
    "\n",
    "print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "print (\"Test Precision: %.2f%%\" % (test_precision * 100.0))\n",
    "print (\"Test Recall: %.2f%%\" % (test_recall * 100.0))\n",
    "print (\"Test f1: %.4f\" % (test_f1))\n",
    "print (\"Test AUC: %.4f\" % (test_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
